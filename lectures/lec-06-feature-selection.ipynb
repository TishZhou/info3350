{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO 3350/6350\n",
    "\n",
    "## Lecture 06: Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "We've spoken before about **overfitting**. A model that is overfit has learned features of the training data that are unlikely to generalize to new, unseen data. As a rule of thumb, a model is very likely to be overfit if it uses on the order of as many features as the training data contains examples. The signature of an overfit model is good performance when evaluated against the training data, but poor performance when evaluated against held-out test data. \n",
    "\n",
    "We also know that models fit to high-dimensional datasets can be difficult to interpret. If we use fewer features (while maintaining good performance), it will generally be easier to explain our system.\n",
    "\n",
    "> **Discuss: How might you go about selecting the best features for a classification task?**\n",
    "\n",
    "Mathematical dimension reduction is one approach to addressing high dimensionality and overfitting. Another is **feature selection**. When we select features to retain in our model, we're looking for ones that seem likely to provide useful information about the relationship between our objects and the class labels we seek to assign. Two useful approaches to feature selection are **ANOVA f-statistics** and **mutual information**. \n",
    "\n",
    "We'll look at both of these methods to estimate feature importance, then see how to use them in `sklearn` to pare down a feature set. We'll also mention **permutation importance**, a strictly *post hoc* empirical measure of feature importance based on the impact to a specified system of ablating individual features.\n",
    "\n",
    "### *F*-statistic and ANOVA analysis\n",
    "\n",
    "We won't say much more about ANOVA analysis; you should have seen it in your stats class. It's conceptually similar to a *t*-test, in that it compares the difference in the means of two groups relative to the variance within each group. A large *F*-statistic means that two samples are significantly different. For feature selection, we want features that are (significantly) differently distributed between the classes.\n",
    "\n",
    "The problem with the *F*-statistic is that it only works well for linear, normally distributed relationships. The advantages are (1) that this assumption is often valid and (2), it's super easy to calculate, so is fast when run on large datasets.\n",
    "\n",
    "### Mutual information\n",
    "\n",
    "**Mutual information** (MI) is abstractly similar to correlation or covariance -- it's a measure of how much two variables change together. But MI doesn't assume a linear relationship between the variables and it's suitable for categorical data, so is often preferred for our purposes.\n",
    "\n",
    "If you want the math, in the case of categorical data (like we're using here with word counts and class labels), mutual information is calculated as:\n",
    "\n",
    "$$MI(U,V)=\\sum_{i=1}^{|U|} \\sum_{j=1}^{|V|}\\frac{|U_i\\cap V_j|}{N}\\log\\frac{N|U_i \\cap V_j|}{|U_i||V_j|}$$\n",
    "\n",
    "Where $\\cap$ indicates the **insection** of two sets. $N$ is the total number of observations in each vector. $i$ and $j$ represent the possible values in each vector. And $|U_i|$ is the count of instances of value $i$ in vector $U$.\n",
    "\n",
    "If we have two vectors, $U = [\\alpha, \\beta]$ and $V = [\\alpha, \\beta]$, we know that our MI score should be high, since $U$ is identical to $V$. For an *n*-class problem, the maximum unnormalized MI is log(*n*). In our example, $N$ = 2 (two observations per vector) and $i$ and $j$ are both drawn from the set $\\{\\alpha,\\beta\\}$. Hence:\n",
    "\n",
    "$$MI(U,V) = \\frac{1}{2}\\log\\frac{2(1)}{1(1)} + 0 + 0 + \\frac{1}{2}\\log\\frac{2(1)}{1(1)} = 0.693147$$\n",
    "\n",
    "The zeros correspond in this example to misaligned labels, of which there are none, hence $|U_i\\cap V_j| = 0$ for all $i\\neq j$ (again, in this specific example of perfect label alignment, not in all cases).\n",
    "\n",
    "Or consider the slightly more interesting case where $U = [1,1,2]$ and $V = [1,2,2]$. In this case, we calculate:\n",
    "\n",
    "$$MI(U,V) = \\frac{1}{3}\\log\\frac{3(1)}{2(1)} + \\frac{1}{3}\\log\\frac{3(1)}{2(2)} + 0 + \\frac{1}{3}\\log\\frac{3(1)}{1(2)} = 0.174416$$\n",
    "\n",
    "Mutual information is often (but not always) reported on a *normalized* basis, in which the raw MI value is divided by log($N$) (or, technically, by the mean entropy of the two variables, but it amounts to the same thing when there are the same number of classes in each variable), the maximum possible MI value for the case. The normalized MI for the first example is 0.693147/log(2) = 1.0. In the second example, normalized MI = 0.174416/log(3) = 0.15876.\n",
    "\n",
    "See the [sklearn documentation for `mutual_info_classif`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import mutual_info_classif, f_classif, SelectKBest\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm hand calculations from above\n",
    "\n",
    "assert np.isclose(\n",
    "    mutual_info_classif(\n",
    "        np.array([[1,0]]).T, # transpose to column vector\n",
    "        np.array([1,0]),\n",
    "        discrete_features=True),\n",
    "    0.693147\n",
    ")\n",
    "assert np.isclose(\n",
    "    mutual_info_classif(\n",
    "        np.array([[1,1,2]]).T, # ditto\n",
    "        np.array([1,2,2]),\n",
    "        discrete_features=True),\n",
    "    0.174416\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo on trivial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f statistic: [4.  0.5]\n",
      "p values: [0.11611652 0.51851852]\n"
     ]
    }
   ],
   "source": [
    "# f-stat\n",
    "X = np.array([[1,1,1,1,0,0], [1,0,1,0,1,0]]).T\n",
    "y = np.array([1,1,1,0,0,0])\n",
    "f_stat, p_vals = f_classif(X,y)\n",
    "print(\"f statistic:\", f_stat)\n",
    "print(\"p values:\", p_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# automated selection\n",
    "SelectKBest(k=1, score_func=f_classif).fit_transform(X,y) # note score_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31825708, 0.05663301])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mutual info\n",
    "mutual_info_classif(X, y, discrete_features=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A small corpus\n",
    "\n",
    "About 125,000 news articles, distributed evenly across four categories (world, business, sports, and science/technology), each trimmed to contain **just the first sentence or two of the original article**. [Data source](https://github.com/mhjabreel/CharCnn_Keras/tree/master/data/ag_news_csv), plus minor massaging into current format.\n",
    "\n",
    "Our task will be to predict the category of any news article using a Bayesian classifier, and to examine the impact of feature selection on model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and clean news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sci_Tech</td>\n",
       "      <td>Mobile phone giant Nokia has unveiled its firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sports</td>\n",
       "      <td>ADELAIDE, Nov 30: Australia crushed New Zealan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Flinching in the trenches, holding around quar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Miami Dolphins owner Wayne Huizenga and presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sci_Tech</td>\n",
       "      <td>InfoWorld - PeopleSoft's Board of Directors vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sci_Tech</td>\n",
       "      <td>AP - Edward Bitet fought in World War II, buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business</td>\n",
       "      <td>LARRY Ellison, the chief executive of software...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sci_Tech</td>\n",
       "      <td>AP - Indonesian police on Tuesday summoned the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>World</td>\n",
       "      <td>AP - Police defused a time-bomb in a town near...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>World</td>\n",
       "      <td>A full season has passed since the UN Security...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sci_Tech</td>\n",
       "      <td>November 03, 2004 - The addictive brutality an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sports</td>\n",
       "      <td>AP - Gerald Williams and Eric Valent hit solo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>World</td>\n",
       "      <td>The Palestinians have taken a double hit this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sci_Tech</td>\n",
       "      <td>Hitachi Global Storage Technologies Inc. and I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sci_Tech</td>\n",
       "      <td>The new desktops, priced between \\$600 and \\$7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sports</td>\n",
       "      <td>by Paul Upham: It was a fight that was to rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Business</td>\n",
       "      <td>NEW YORK (Reuters) - Kraft Foods Inc. &amp;lt;A H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sports</td>\n",
       "      <td>AP - Jordan Palmer threw a 25-yard touchdown p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sci_Tech</td>\n",
       "      <td>The Open Source Development Labs has gone into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sports</td>\n",
       "      <td>AP - Jeff Brehaut shot an 11-under 61 Friday a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               body\n",
       "0   Sci_Tech  Mobile phone giant Nokia has unveiled its firs...\n",
       "1     Sports  ADELAIDE, Nov 30: Australia crushed New Zealan...\n",
       "2     Sports  Flinching in the trenches, holding around quar...\n",
       "3     Sports  Miami Dolphins owner Wayne Huizenga and presid...\n",
       "4   Sci_Tech  InfoWorld - PeopleSoft's Board of Directors vo...\n",
       "5   Sci_Tech  AP - Edward Bitet fought in World War II, buil...\n",
       "6   Business  LARRY Ellison, the chief executive of software...\n",
       "7   Sci_Tech  AP - Indonesian police on Tuesday summoned the...\n",
       "8      World  AP - Police defused a time-bomb in a town near...\n",
       "9      World  A full season has passed since the UN Security...\n",
       "10  Sci_Tech  November 03, 2004 - The addictive brutality an...\n",
       "11    Sports  AP - Gerald Williams and Eric Valent hit solo ...\n",
       "12     World  The Palestinians have taken a double hit this ...\n",
       "13  Sci_Tech  Hitachi Global Storage Technologies Inc. and I...\n",
       "14  Sci_Tech  The new desktops, priced between \\$600 and \\$7...\n",
       "15    Sports  by Paul Upham: It was a fight that was to rece...\n",
       "16  Business   NEW YORK (Reuters) - Kraft Foods Inc. &lt;A H...\n",
       "17    Sports  AP - Jordan Palmer threw a 25-yard touchdown p...\n",
       "18  Sci_Tech  The Open Source Development Labs has gone into...\n",
       "19    Sports  AP - Jeff Brehaut shot an 11-under 61 Friday a..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data from disk and examine\n",
    "news = pd.read_csv(os.path.join('..', 'data', 'news', 'news_text.csv.gz'))\n",
    "news.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I bet those datelines will be a problem. Let's get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a function to get rid of datelines at the start of articles\n",
    "#  matches one or more hyphens or colons in first 40 chars,\n",
    "#  drops everything before that match (plus the match itself)\n",
    "pattern = '[-:]+ '\n",
    "matcher = re.compile(pattern) # compiled regexs are faster\n",
    "\n",
    "def remove_dateline(text, matcher=matcher):\n",
    "    '''\n",
    "    Remove source names and datelines from a text string\n",
    "    If there is a hyphen or colon in the first 40 characters, \n",
    "      drops everything before the hyphen(s)/colon(s)\n",
    "    If no hyphen/colon, do nothing\n",
    "    Return processed string\n",
    "    '''\n",
    "    result = matcher.search(text, endpos=40)\n",
    "    if result:\n",
    "        return text[result.end():]\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean article text\n",
    "news['body'] = news['body'].apply(remove_dateline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sci_Tech</td>\n",
       "      <td>Mobile phone giant Nokia has unveiled its firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Australia crushed New Zealand by 213 runs on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Flinching in the trenches, holding around quar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Miami Dolphins owner Wayne Huizenga and presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sci_Tech</td>\n",
       "      <td>PeopleSoft's Board of Directors voted Wednesda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sci_Tech</td>\n",
       "      <td>Edward Bitet fought in World War II, built aff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business</td>\n",
       "      <td>LARRY Ellison, the chief executive of software...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sci_Tech</td>\n",
       "      <td>Indonesian police on Tuesday summoned the Amer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>World</td>\n",
       "      <td>Police defused a time-bomb in a town near Prim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>World</td>\n",
       "      <td>A full season has passed since the UN Security...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sci_Tech</td>\n",
       "      <td>The addictive brutality and enveloping strateg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Gerald Williams and Eric Valent hit solo home ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>World</td>\n",
       "      <td>The Palestinians have taken a double hit this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sci_Tech</td>\n",
       "      <td>Hitachi Global Storage Technologies Inc. and I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sci_Tech</td>\n",
       "      <td>The new desktops, priced between \\$600 and \\$7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sports</td>\n",
       "      <td>It was a fight that was to receive national ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Business</td>\n",
       "      <td>Kraft Foods Inc. &amp;lt;A HREF=\"http://www.invest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Jordan Palmer threw a 25-yard touchdown pass t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sci_Tech</td>\n",
       "      <td>The Open Source Development Labs has gone into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Jeff Brehaut shot an 11-under 61 Friday and to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               body\n",
       "0   Sci_Tech  Mobile phone giant Nokia has unveiled its firs...\n",
       "1     Sports  Australia crushed New Zealand by 213 runs on t...\n",
       "2     Sports  Flinching in the trenches, holding around quar...\n",
       "3     Sports  Miami Dolphins owner Wayne Huizenga and presid...\n",
       "4   Sci_Tech  PeopleSoft's Board of Directors voted Wednesda...\n",
       "5   Sci_Tech  Edward Bitet fought in World War II, built aff...\n",
       "6   Business  LARRY Ellison, the chief executive of software...\n",
       "7   Sci_Tech  Indonesian police on Tuesday summoned the Amer...\n",
       "8      World  Police defused a time-bomb in a town near Prim...\n",
       "9      World  A full season has passed since the UN Security...\n",
       "10  Sci_Tech  The addictive brutality and enveloping strateg...\n",
       "11    Sports  Gerald Williams and Eric Valent hit solo home ...\n",
       "12     World  The Palestinians have taken a double hit this ...\n",
       "13  Sci_Tech  Hitachi Global Storage Technologies Inc. and I...\n",
       "14  Sci_Tech  The new desktops, priced between \\$600 and \\$7...\n",
       "15    Sports  It was a fight that was to receive national ex...\n",
       "16  Business  Kraft Foods Inc. &lt;A HREF=\"http://www.invest...\n",
       "17    Sports  Jordan Palmer threw a 25-yard touchdown pass t...\n",
       "18  Sci_Tech  The Open Source Development Labs has gone into...\n",
       "19    Sports  Jeff Brehaut shot an 11-under 61 Friday and to..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm articles are cleaned\n",
    "news.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute token counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127600, 3486)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up a vectorizer object\n",
    "count_vectorizer = CountVectorizer(\n",
    "    strip_accents='unicode', # collapse accents to base character\n",
    "    stop_words=None, # do not remove stop words\n",
    "    binary=False, # do not binarize features\n",
    "    #max_features=1000,\n",
    "    min_df=0.001 # limit features to those that occur in at least 0.1% of articles\n",
    ")\n",
    "\n",
    "# perform vectorization\n",
    "X = count_vectorizer.fit_transform(news['body'])\n",
    "\n",
    "# vectorized shape\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['amd', 'america', 'american', 'americans', 'amid', 'among',\n",
       "       'amount', 'amp', 'an', 'anaheim'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what do the columns measure?\n",
    "count_vectorizer.get_feature_names_out()[200:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3216050"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total word count in our corpus?\n",
    "X.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corpus isn't very big. Or, well, the documents are pretty short, on average: 3.2M words / 127k documents = about 25 words per document. This fact will make classification a little harder than it would be if we had full documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify sports (vs everything else)\n",
    "\n",
    "We'll try **Bernouli naïve Bayes**, **Multinomial naïve Bayes**, and **Gaussian naïve Bayes** classifiers. The difference is that the Bernouli version first transforms our input features into ones and zeros, thereby coding for the presence or absence of each word in each document (but not accounting for how many times the word occurs in the document). Multinomial NB does not binarize inputs, so accounts for the number of occurrences. But Multinomial NB *does* expect nonnegative integers as input. Gaussian NB works with continuous inputs.\n",
    "\n",
    "There's no principled reason to prefer Bernouli, multinomial, or Gaussian NB. Use whichever one produces better results on your data (and is suitable for the type of input data you're using). Bernouli can be useful in the case where most documents use any word only a few times at most, rare documents use some words very many times, but you don't consider the rare, high-usage documents to be fundamentally unlike the other documents that use the same words just a few times.\n",
    "\n",
    "**Remember:** when we call `.fit()` (as we do explicitly here, or under the hood of `cross_val_score`, for example), what we're learning are the empirical probabilities of each word in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sci_Tech', 'Sports', 'Business', 'World'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Sci_Tech    31900\n",
       "Sports      31900\n",
       "Business    31900\n",
       "World       31900\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make boolean array of sports/other labels\n",
    "y = news['label'] == 'Sports'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127600,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "# --> limit to 1000 articles for demo purposes <--\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:1000], y[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on TRAINING data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.97      0.98       567\n",
      "        True       0.92      0.99      0.96       183\n",
      "\n",
      "    accuracy                           0.98       750\n",
      "   macro avg       0.96      0.98      0.97       750\n",
      "weighted avg       0.98      0.98      0.98       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# score BernouliNB classifier on train and test data\n",
    "clf = BernoulliNB().fit(X_train, y_train)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print(\"Performance on TRAINING data\")\n",
    "print(classification_report(y_train_pred, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on TEST data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.93      0.95       197\n",
      "        True       0.77      0.91      0.83        53\n",
      "\n",
      "    accuracy                           0.92       250\n",
      "   macro avg       0.87      0.92      0.89       250\n",
      "weighted avg       0.93      0.92      0.93       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "print(\"Performance on TEST data\")\n",
    "print(classification_report(y_test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is evidence of overfitting in this case, because we perform significantly better when we make preditions on the training data than when we do the same on held-out test data\n",
    "\n",
    "How about in the multinomial case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on TRAINING data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      1.00      1.00       549\n",
      "        True       0.99      0.98      0.99       201\n",
      "\n",
      "    accuracy                           0.99       750\n",
      "   macro avg       0.99      0.99      0.99       750\n",
      "weighted avg       0.99      0.99      0.99       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# score Multinomial classifier on train and test data\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print(\"Performance on TRAINING data\")\n",
    "print(classification_report(y_train_pred, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on TEST data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.97      0.93       176\n",
      "        True       0.90      0.76      0.82        74\n",
      "\n",
      "    accuracy                           0.90       250\n",
      "   macro avg       0.90      0.86      0.88       250\n",
      "weighted avg       0.90      0.90      0.90       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "print(\"Performance on TEST data\")\n",
    "print(classification_report(y_test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial NB performs just a tiny bit better in this case, but not enough to matter, really. And we're obviously still overfitting.\n",
    "\n",
    "Aside: One reason to like NB classifiers is that they're really fast. Sklearn's NB classifiers are over 100 times faster than logistic regression on the same task (and they produce comparable accuracy). This equivalent accuracy won't always be true, of course, but the speedup can be a big plus with large datasets.\n",
    "\n",
    "Bernouli NB is slower than multinomial NB due to binarization overhead. But the difference is trivial here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the most informative features\n",
    "\n",
    "Let's see how well we can do with lower-dimension inputs. We'll do this in two ways:\n",
    "\n",
    "1. Rank the input features (token counts) according to the degree to which their presence/absence matches the presence/absence of the `sports` class label. High mutual information between tokens and class labels suggests that a token will be a useful feature for our classifier. We'll also evaluate the *F*-statistic as a criterion and try out permutation importance, too.\n",
    "\n",
    "2. We'll also try dimension reduction via Truncated SVD, as we studied in previous lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 951 ms, sys: 2.65 ms, total: 953 ms\n",
      "Wall time: 953 ms\n"
     ]
    }
   ],
   "source": [
    "# calculate mutual info scores btw each feature and the target label\n",
    "%time mi = mutual_info_classif(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not fast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3486,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.28050655e-03, 4.07286441e-03, 1.12414185e-05, ...,\n",
       "       3.56143801e-03, 1.42083804e-03, 4.09019389e-04])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1636, 3131,  810, ...,  471, 3071, 2963])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get indices of mi array, sorted from highest to lowest mutual info\n",
    "mi_indices = np.flip(mi.argsort()) # np.flip reverses order; want high -> low\n",
    "mi_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discuss**: What do you expect to be some of the most informative features (words) for the **sports** catengory? That is, what words occurs often in sports stories, but not very often in other kinds of news articles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'its'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the single most informative sports feature\n",
    "count_vectorizer.get_feature_names_out()[mi_indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['its', 'the', 'cup', 'game', 'league', 'company', 'victory',\n",
       "       'play', 'scored', 'night'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the feature data and column labels\n",
    "X_train_sorted = X_train[:, mi_indices]\n",
    "X_test_sorted = X_test[:, mi_indices]\n",
    "features_sorted = np.array(count_vectorizer.get_feature_names_out())[mi_indices]\n",
    "features_sorted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.93      0.95       195\n",
      "        True       0.77      0.87      0.82        55\n",
      "\n",
      "    accuracy                           0.92       250\n",
      "   macro avg       0.87      0.90      0.88       250\n",
      "weighted avg       0.92      0.92      0.92       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# performance with top 100 features\n",
    "clf = MultinomialNB().fit(X_train_sorted[:,:100], y_train)\n",
    "y_pred = clf.predict(X_test_sorted[:,:100])\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we've suffered just a few points of weighted average F1 decrease despite throwing away all but 100 out of c. 3,500 original features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how performance responds in input feature dimensionality in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# how does performance respond to number of features used?\n",
    "num_features = [2**i for i in range(1,10)]\n",
    "f1s = []\n",
    "for i in num_features:\n",
    "    clf = MultinomialNB().fit(X_train_sorted[:,:i], y_train)\n",
    "    y_pred = clf.predict(X_test_sorted[:,:i])\n",
    "    f1s.append(f1_score(y_pred, y_test, average='weighted'))\n",
    "\n",
    "plt.scatter(num_features, f1s)\n",
    "plt.xlabel(\"Number of features used\")\n",
    "plt.ylabel(\"f1 score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In practice\n",
    "\n",
    "Split into train and test, fit a model, predict class labels, and examine classification errors. This is a typical workflow in production.\n",
    "\n",
    "We can make things a little easier by using the `SelectKBest` method, which handles all of the sorting and indexing that we performed by hand above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.93      0.95       195\n",
      "        True       0.77      0.87      0.82        55\n",
      "\n",
      "    accuracy                           0.92       250\n",
      "   macro avg       0.87      0.90      0.88       250\n",
      "weighted avg       0.92      0.92      0.92       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using the n most-informative features\n",
    "\n",
    "# fit selector\n",
    "n_features = 100\n",
    "selector = SelectKBest(k=n_features, score_func=mutual_info_classif).fit(X_train, y_train)\n",
    "\n",
    "# select best features\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# fit and predict\n",
    "clf = MultinomialNB().fit(X_train_selected, y_train)\n",
    "y_pred = clf.predict(X_test_selected)\n",
    "\n",
    "# examine performance\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Prosecutors in the Kobe Bryant rape case will ask a judge on Wednesday to drop the rape charge against the basketball player, a source close to the case said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>Sports</td>\n",
       "      <td>The University of Rhode Island football team, in pursuit of its first winning season in three years and just its third since 1992, took a step in that direction last Saturday with its 27-24 victory over Massachusetts in Kingston, R.I.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>World</td>\n",
       "      <td>Bookies take bets on a new Band Aid single being Christmas No 1, expected to be confirmed by Midge Ure.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Bowden replaced starting quarterback Wyatt Sexton with Chris Rix at the beginning of the fourth quarter, with FSU trailing 20-10.  quot;I definitely wasn #39;t expecting it, quot; Sexton said,  quot;but I understood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>World</td>\n",
       "      <td>Every Friday, 17-year-old Dhari al-Zahameel's family would wait for him to come back from the mosque so they could have lunch together. Then one day the young al-Zahameel didn't come home, instead sending word he had gone to fight in the jihad, or holy war.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  \\\n",
       "927  Sports   \n",
       "478  Sports   \n",
       "898  World    \n",
       "587  Sports   \n",
       "765  World    \n",
       "\n",
       "                                                                                                                                                                                                                                                                  body  \n",
       "927  Prosecutors in the Kobe Bryant rape case will ask a judge on Wednesday to drop the rape charge against the basketball player, a source close to the case said.                                                                                                     \n",
       "478  The University of Rhode Island football team, in pursuit of its first winning season in three years and just its third since 1992, took a step in that direction last Saturday with its 27-24 victory over Massachusetts in Kingston, R.I.                         \n",
       "898  Bookies take bets on a new Band Aid single being Christmas No 1, expected to be confirmed by Midge Ure.                                                                                                                                                            \n",
       "587  Bowden replaced starting quarterback Wyatt Sexton with Chris Rix at the beginning of the fourth quarter, with FSU trailing 20-10.  quot;I definitely wasn #39;t expecting it, quot; Sexton said,  quot;but I understood                                            \n",
       "765  Every Friday, 17-year-old Dhari al-Zahameel's family would wait for him to come back from the mosque so they could have lunch together. Then one day the young al-Zahameel didn't come home, instead sending word he had gone to fight in the jihad, or holy war.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select erroneous predictions\n",
    "errors = y_test != y_pred             # boolean array of gold/pred mismatches\n",
    "errors = np.where(errors==True)       # index array of test set error locations\n",
    "error_index = y_test.index[errors[0]] # map test-set error positions to original indices\n",
    "\n",
    "news_errors = news.loc[error_index, ['label', 'body']] # select errors from original data\n",
    "\n",
    "with pd.option_context('display.max_colwidth', 0): # display errors\n",
    "    display(news_errors.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Truncated SVD\n",
    "\n",
    "Compare performance using SVD in place of most-informative features.\n",
    "\n",
    "In lecture, we talked about **standardizing** our input features before performing SVD, so that the variance isn't dominated simply by high-frequency words (in this case, words like \"and\" and \"the\" - we didn't perform stopword removal). Here, we're going to skip that step, so that we can preserve input sparsity (hence, computational and memory efficiency).\n",
    "\n",
    "If we *were* going to standradize our features, we'd do something like:\n",
    "\n",
    "```\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.toarray()) # cast input to dense array\n",
    "```\n",
    "We would need to transform our input matrix to dense format with `.toarray()`, since `StandardScaler` refuses to break sparsity. And if we were going to do all that, we'd be performing PCA anyway, so we'd just use PCA in that case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 100)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce input dimensionality\n",
    "reducer = TruncatedSVD(n_components=100)\n",
    "X_train_reduced = reducer.fit_transform(X_train)\n",
    "X_test_reduced = reducer.transform(X_test)\n",
    "X_train_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.17887697e+00, -2.82040486e-01,  6.06170745e-01,  1.97262125e+00,\n",
       "        1.25007347e+00, -1.00234434e+00, -2.68963818e-01,  3.87851126e-01,\n",
       "       -5.96338075e-01,  5.89099447e-03,  1.89035576e-01, -3.74814450e-01,\n",
       "       -2.75998502e-01,  3.26121087e-01, -1.73551063e-01, -5.02756505e-01,\n",
       "        1.35743882e-01,  2.17088047e-01, -4.24478816e-01, -2.08982460e-01,\n",
       "        6.98596798e-02, -1.44565271e-01, -5.61435551e-02,  1.43842020e+00,\n",
       "       -2.15170688e-02,  6.75626991e-01,  6.62475901e-01,  1.44690448e-01,\n",
       "        2.47158459e-01, -4.11627615e-01, -4.97312927e-01,  3.26051081e-01,\n",
       "       -2.59190867e-01, -7.63391178e-01,  5.48671717e-01, -2.21569773e-01,\n",
       "       -6.50653979e-01,  1.08889836e-01,  5.84208517e-01, -7.30722219e-01,\n",
       "        7.94143816e-02,  6.03414704e-01,  5.16843922e-01, -4.28994704e-01,\n",
       "       -6.59576257e-02, -4.39379702e-01, -1.46588303e-01,  6.94442983e-02,\n",
       "       -5.81985309e-01,  4.09098332e-01,  3.80886875e-01, -3.42842109e-01,\n",
       "       -6.13805704e-01, -4.82891760e-02, -8.14874327e-01,  4.15498018e-02,\n",
       "        5.71485605e-03, -9.97409265e-02,  5.68524623e-01, -3.90071548e-01,\n",
       "       -2.56750840e-02,  3.27471295e-01, -3.42504024e-01, -2.08538514e-01,\n",
       "        4.49454171e-01,  3.82295121e-01, -1.89036950e-01,  6.72308026e-02,\n",
       "       -1.15140758e-01, -4.03167975e-01, -1.56478133e-01, -4.16493805e-01,\n",
       "       -7.46335047e-02, -1.22889497e-01,  5.16701897e-01, -1.96818280e-01,\n",
       "       -4.80120460e-02,  1.88295490e-01, -2.47653615e-01, -1.11307169e-01,\n",
       "        1.78737328e-02,  2.64810749e-01, -2.92585123e-01,  3.90239677e-01,\n",
       "       -1.58101872e-01, -7.19784627e-02, -6.04776030e-01, -5.18375017e-04,\n",
       "       -1.28747544e-01,  1.13936508e-01,  8.00012639e-01,  8.79497315e-02,\n",
       "       -1.25654326e-01, -6.90580675e-01, -8.22073432e-02, -1.59424421e-01,\n",
       "        1.30722469e-01,  2.84179781e-01,  5.67126112e-01,  2.16150144e-01])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine new features for the first document\n",
    "X_train_reduced[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00457805,  0.01013013,  0.00275201, ...,  0.00143899,\n",
       "         0.00203529,  0.00075856],\n",
       "       [ 0.00735276,  0.00946863,  0.00523284, ..., -0.00064886,\n",
       "        -0.00197156,  0.00050272],\n",
       "       [-0.00333199, -0.00923093, -0.00691818, ..., -0.00028153,\n",
       "        -0.00092459, -0.00110942],\n",
       "       ...,\n",
       "       [ 0.01448162, -0.03675606, -0.01159406, ...,  0.01406392,\n",
       "         0.00727159,  0.00418391],\n",
       "       [ 0.01275771, -0.04226691,  0.02170155, ..., -0.0062714 ,\n",
       "        -0.02905867,  0.00215009],\n",
       "       [-0.02542422,  0.01572511, -0.01570823, ..., -0.0101239 ,\n",
       "         0.00453163,  0.00117253]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# could examine loadings\n",
    "reducer.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3486,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loadings are distributed over all input features\n",
    "reducer.components_[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.84      0.86       193\n",
      "        True       0.52      0.56      0.54        57\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.69      0.70      0.70       250\n",
      "weighted avg       0.79      0.78      0.78       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# performace using top SVD components\n",
    "clf = GaussianNB().fit(X_train_reduced, y_train)\n",
    "y_pred = clf.predict(X_test_reduced)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to use `GaussianNB`, because multinomial NB (as the name suggests) expects purely positive, integer-valued inputs. Gaussian NB accepts all real-valued inputs.\n",
    "\n",
    "Performance here isn't as good as it was when we used the top 100 **sports-specific** features (recall that our task is **sports** classification). But the SVD features were more than an order of magnitude faster to calculate and, more importantly, should be useful if we wanted to classify any of the other categories (because the SVD dimensions capture overall variance in the data, rather than being tied to any specific category). \n",
    "\n",
    "As it turns out *in this case*, that isn't really true: top sports features outperform SVD in the sports case, but are surprisingly close to SVD performance for the other categories, too. Think about why this might be true in the special case of language data? (High dimensionality, correlated features, lots of nonuniform structure in the data; 100 features are a *lot* for just 1k observations). If you're interested, you might try to implement these evaluations for yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permutation importance\n",
    "\n",
    "Permutation importance measures the impact on classifier performance of rendering a feature *uninformative*. The idea is that a feature is important if removing it tanks classification performance. Specifically, we will *permute* (shuffle) the values contained in a feature vector, breaking any possible association between those values and the target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.41 s, sys: 980 ms, total: 6.39 s\n",
      "Wall time: 4.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = MultinomialNB().fit(X_train_selected, y_train)\n",
    "\n",
    "r = permutation_importance(\n",
    "    clf, \n",
    "    X_test_selected.toarray(), # expects dense input \n",
    "    y_test,\n",
    "    scoring='f1_weighted',\n",
    "    n_repeats=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation feature importance:\n",
      "\n",
      "     yankees  0.021 +/- 0.005\n",
      "        that  0.021 +/- 0.006\n",
      "         cup  0.019 +/- 0.005\n",
      "         its  0.018 +/- 0.008\n",
      "        game  0.015 +/- 0.006\n",
      "       plans  0.010 +/- 0.004\n",
      "    security  0.010 +/- 0.005\n",
      "      season  0.010 +/- 0.004\n",
      "      league  0.010 +/- 0.005\n",
      "       coach  0.008 +/- 0.004\n",
      "       night  0.008 +/- 0.006\n",
      "         oil  0.008 +/- 0.005\n",
      "     company  0.008 +/- 0.005\n",
      "         win  0.007 +/- 0.004\n",
      "     players  0.007 +/- 0.004\n",
      "        team  0.007 +/- 0.004\n",
      "          he  0.007 +/- 0.004\n",
      "       round  0.007 +/- 0.004\n",
      "       their  0.007 +/- 0.004\n",
      "       games  0.007 +/- 0.003\n",
      "         sox  0.005 +/- 0.005\n",
      "        prix  0.005 +/- 0.002\n",
      "   microsoft  0.005 +/- 0.003\n"
     ]
    }
   ],
   "source": [
    "print(\"Permutation feature importance:\\n\")\n",
    "\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    # only display significant features\n",
    "    if r.importances_mean[i] - 1 * r.importances_std[i] > 0:\n",
    "        word = count_vectorizer.get_feature_names_out()[int(selector.get_feature_names_out()[i].strip('x'))]\n",
    "        print(f\"{word:>12}  {r.importances_mean[i]:.3f} +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
