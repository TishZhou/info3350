{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO 3350/6350\n",
    "\n",
    "## Lecture 12: Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks and deep learning\n",
    "\n",
    "* We've used NLP tools at many points this semester, but this isn't an NLP class\n",
    "* That said, neural methods have transformed many areas of NLP over the last decade\n",
    "    * And deep learning -- a subset of neural methods -- has been very widely applied in machine learning and AI\n",
    "* Our tasks today: define \"neural network,\" relate neural nets to other learning systems, take a look at how a neural network works, and show how to implement a very simple neural classifier in Python\n",
    "\n",
    "### What is a neural network?\n",
    "\n",
    "* A neural network is a computing system comprising artificial neurons\n",
    "* Neurons were originally (1940s) intended to model organic brain behavior\n",
    "    * But now, the name is really just a bit of jargon. No one thinks its important whether or not computational neurons have anything to do with biological neurons.\n",
    "* Individual neurons are mathematical functions that take a vector of input values and produce a single output value.\n",
    "    * We've seen lots of these kinds of functions over the semester, not all of them related to actually existing neural networks\n",
    "    * What matters are the details of the functions and the ways they relate to one another in a network\n",
    "* In a neural network, the neurons are connected to one another in one or more layers, so that the output of one neuron is the input of another (or many others)\n",
    "    \n",
    "### Logistic regression\n",
    "\n",
    "* Logistic regression **is not a neural network** in the modern sense, but it captures much of the spirit of a basic neural network and a lot of the math is related, so let's revisit it\n",
    "* Fit training data to a linear model: $z = W_0 + W_1 x_1 + W_2 x_2 + ...$\n",
    "    * Values of $x\\ $ are observed properties of an object (counts of individual words, say)\n",
    "    * The $W\\ $ s are weights. We multiply the weight associated with each word (for example) by the number of times that word occurs in a document.\n",
    "        * These types of element-wise multiplications between two vectors are called **dot products**\n",
    "    * Add up the weight * count products and we produce an output value, $z$\n",
    "    * Note that values of $z$ can range from -infinity to +infinity\n",
    "* Transform the linear value into a score between 0 and 1 using the sigmoid function: $$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "* Sigmoid function looks like this:\n",
    "    \n",
    "<img src=\"./images/sigmoid.png\">\n",
    "\n",
    "* When we train a logistic regression classifier, we're trying to learn the set of weights that produce the most accurate classifications\n",
    "* We learn the weights by:\n",
    "    * Initializing to random values (or equal values, or some arrangement that reflects our best guess about the correct weights)\n",
    "    * Calculating **cross-entropy loss**, that is, how far away are our predicted outputs from the known-true (gold) values.\n",
    "        * Our goal is to minimize this loss function by adjusting the weights in our model\n",
    "        * See Jurafsky and Martin, ch. 5 (\"Logistic Regression\"), for the math, but the short version is that we take (roughly) the negative log of the sum of the differences between the predicted labels (as probabilities ranging from 0 to 1) and the true labels (which are either 0 or 1)\n",
    "        * Trivia point: logistic regression is a more advanced version of the **perceptron** (which uses a binary loss function rather than a probabilistic one). The perceptron was invented at Cornell (by Frank Rosenblatt in 1958).\n",
    "    * Adjusting our weights using **gradient descent**\n",
    "        * Again, the math isn't important to us, but ... we find the gradient (slope) of the loss function by partial differentiation with respect to each of the weights. In short, we find how the loss function chages in response to small changes in each weight, then move the weight in the direction that minimizes the loss. Repeat until the loss function stops changing (much) and hope we've found the global minimum (that is, the globally best weights).\n",
    "* If you've been around neural networks and machine learning, these terms will sound familiar: loss function, gradient descent. Now you know what they mean.\n",
    "\n",
    "### From logistic regression to feed-forward networks\n",
    "\n",
    "* The problem with logistic regression (which is a great classifier for many problems!) is that it can only learn linear relationships between inputs and outputs. If our problem is nonlinear, logistic regression might not work well on it.\n",
    "* The simplest way to understand the relationship between logistic regression and a basic neural network is that a neural network is made up of multiple logistic-like functions, each of which can learn a different part of the correct solution (where \"solution\" = function that best fits the training data)\n",
    "* Here's a schematic representation (from Jurafsky and Martin) of a feed-forward network with a single hidden layer (the middle one, with labels $h_i$):\n",
    "\n",
    "<img src=\"./images/neural_network.png\">\n",
    "\n",
    "* There are three layers here: input, hidden, and output.\n",
    "    * The input layer is the data you feed into the system.\n",
    "    * The hidden layer is where the weights are adjusted to maximize classification accuracy. This is what *learns*.\n",
    "    * The output layer translates numerical values calculated in the hidden layer into class probabilities (that is, into specific classification decisions).\n",
    "* The math in this case is the same as in the logistic case, except that:\n",
    "    * We have matrices of weights across the neurons, rather than a single vector of weights for a single neuron\n",
    "    * We have a vector of outputs from the hidden layer, rather a single, scalar output\n",
    "    * Gradient descent is harder, because there are more paths to differentiate\n",
    "        * This is the most consequential difference in practical terms, because it really slows down training\n",
    "        * The standard approach is **backpropagation**. For details, See Jurafsky and Martin, ch. 7 (\"Neural Networks\"). It's like partial differentiation, but performed piece-wise backward through the all the possible paths from outputs to inputs via the hidden layer(s). \n",
    "        \n",
    "### From shallow to deep\n",
    "\n",
    "* Even a neural network with a single hidden layer (of possibly infinite width; that is, made up of arbitrarily many neurons) can be shown to be able to represent a function of arbitrary complexity\n",
    "    * Note in passing: this is a remarkable result. It means that neural networks are immensely flexible in the relationships between inputs and outputs that they can model.\n",
    "    * But this fact doesn't imply that it's *easy* to learn a correct or high-performing representation of an arbitrary function in a neural network\n",
    "* In practice, it can be (sometimes!) more efficient to build networks that are narrower but *deeper*; that have more layers\n",
    "* Deep learning also largely removes the need for (certain kinds of) feature engineering, since the layers learn maximally effective transformations of the data\n",
    "    * But the right kinds of data still need to be present in the first place!\n",
    "    * If you only give your network word counts, it won't magically engineer paratextual features.\n",
    "* You may have heard of **convolutional** neural networks and **recurrent** neural networks. These are networks in which there is not a strict one-to-one connection between all the neurons in each layer.\n",
    "    * Convolutional networks are (or, were) widely used in image recognition\n",
    "    * Recurrent networks (in which parts of layers are connected both forward and backward) are (again, were) often used in NLP applications\n",
    "* All of this is **slow** and involves a lot of matrix math. Two main factors have driven the deep learning revolution over the last two decades:\n",
    "    * Web-scale data, which provides enough instances to learn fine distinctions in complex decision boundaries\n",
    "        * A method that can model arbitrarily complex functions isn't much good if you don't have enough data to explore the function space\n",
    "    * GPUs (graphics cards), which are essentially super-fast matrix calculators\n",
    "        * These make computing with all that data tractable (more or less)\n",
    "* More recently, we've discovered that we can do without recurrence or convolution, provided we have enough data. This is the insight behind the transformer architecture, BERT, and all that has followed. We'll have more to say about that in future lectures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic neural network classification in `torch`\n",
    "\n",
    "Again, this isn't an actual ML or NLP course. However, since today's language models are often PyTorch models under the hood, it's good to have a high-level understanding of how PyTorch works. Building an MLP is a great way to get comfortable with the \"building blocks\" of neural networks using this library.\n",
    "\n",
    "We won't be focussing on our results too much (we're running this live in class, after all). Instead, try to focus on what each part of the code is doing, given the preceding introduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn    \n",
    "from torch.nn import functional as F    # This is the \"numpy as np\" of torch, so to speak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch makes building neural nets very easy, since we don't have to keep track of weights and gradients ourselves. For instance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer weight matrix:  torch.Size([32, 128])\n",
      "Layer bias vector:  torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "linear_layer = nn.Linear(128, 32) # (input_dim, output_dim)\n",
    "\n",
    "print(\"Layer weight matrix: \", linear_layer.weight.shape)\n",
    "print(\"Layer bias vector: \", linear_layer.bias.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that a layer in an MLP has the form $$y=\\sigma(xW^T + b)$$ where $x$ is our input, $W$ is our weight matrix, $b$ is our bias vector, and $\\sigma$ is our activation function. This `nn.Linear` takes care of our $W$ and $b$ for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7018,  0.4108,  0.1057, -0.4428, -0.1365, -0.9067,  0.0938,  0.0203,\n",
      "         0.4078, -0.4836,  0.2091,  0.8099, -0.2679, -0.2801, -0.0483, -0.8730,\n",
      "         0.1560, -0.1477, -0.5156, -0.5034,  1.0639, -0.7810, -0.9566,  0.4746,\n",
      "        -1.0741, -0.2438,  0.1191, -0.8212, -0.3253,  0.0122,  0.0969,  0.1733],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "torch.Size([5, 32])\n",
      "Requires grad? True\n",
      "Max:  tensor(1.4688, grad_fn=<MaxBackward1>)\n",
      "Min:  tensor(-1.4006, grad_fn=<MinBackward1>)\n"
     ]
    }
   ],
   "source": [
    "random_input = torch.randn((5, 128))\n",
    "layer_output = linear_layer(random_input)\n",
    "\n",
    "print(layer_output[0])\n",
    "print(layer_output.shape)\n",
    "print(\"Requires grad?\", layer_output.requires_grad)\n",
    "print(\"Max: \", layer_output.max())\n",
    "print(\"Min: \", layer_output.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we can see that our linear layer handles the $xW^T + b$ for us. \n",
    "\n",
    "We can also see that `torch` will \"keep track\" of gradients for us, unless we tell it otherwise. This is important for training, but when evaluating or running our model after it is trained, we don't need gradients to be computed. We can turn off autograd using a context manager like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3083,  0.2552, -0.0056, -0.3120, -0.5979, -1.2972, -0.1849, -0.0836,\n",
      "         1.8068,  0.4168,  0.5786,  0.0855,  0.5496, -0.2219, -0.3818, -1.6394,\n",
      "         0.6022,  1.1264, -0.0752, -0.4198,  0.2587,  0.9473,  0.2984, -1.2766,\n",
      "        -0.8682,  0.6112, -0.4562, -0.4195, -1.0250, -0.8220,  0.2453,  0.0118])\n",
      "Requires grad? False\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():    \n",
    "    random_input = torch.randn((5, 128))\n",
    "    layer_output = linear_layer(random_input)\n",
    "    print(layer_output[0])\n",
    "    print(\"Requires grad?\", layer_output.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be important later!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `Linear` layer handles the weights and bias term, but we still need an activation function to build a real MLP. PyTorch has a bunch of built-in activation functions, which can be treated as a layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 0.8589800000190735\n",
      "Min: 0.1625528186559677\n"
     ]
    }
   ],
   "source": [
    "sigma = nn.Sigmoid()\n",
    "\n",
    "with torch.no_grad(): \n",
    "    sigmoid_output = sigma(layer_output)\n",
    "\n",
    "sig_max = sigmoid_output.max()\n",
    "sig_min = sigmoid_output.min()\n",
    "\n",
    "print(f\"Max: {sig_max}\\nMin: {sig_min}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    f_sig_output = F.sigmoid(layer_output)\n",
    "\n",
    "assert torch.allclose(sigmoid_output, f_sig_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One reason to use `nn.Sigmoid` over `F.sigmoid` is illustrated below:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4971])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_of_layers = nn.Sequential(\n",
    "    nn.Linear(32, 64),\n",
    "    nn.ReLU(),      # Rectified linear unit (another act. fn.)\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 1),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    stack_output = stack_of_layers(torch.randn((32)))\n",
    "\n",
    "stack_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That `stack_of_layers` is an MLP! `nn.Sequential` takes a sequence of layers (more specifically, PyTorch objects that subclass `nn.Module`) and chains them together.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (5): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_of_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So while we could build an MLP using `nn.Sequential`, you could (and probably should) define your model as a subclass of `nn.Module`. Subclasses of `nn.Module` must override the `__init__` and `forward` methods. This makes sense, since `__init__` initializes our model with some layers, and `forward` defines how data moves through those layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFirstMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.fc_1 = nn.Linear(input_dim, hidden_dim) # Layer 1\n",
    "        self.fc_2 = nn.Linear(hidden_dim, 1) # Layer 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.fc_1(x))          # h = ReLU(xW1_T + b)\n",
    "        return F.sigmoid(self.fc_2(h))    # y_hat = Sigmoid(hW2_T + b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also do something like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusing modules, using nn.Sequential inside a module, and \n",
    "# passing functions around...\n",
    "\n",
    "class MLPLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, act_fn): \n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        self.act_fn = act_fn\n",
    "    \n",
    "    def forward(self, x): \n",
    "        return self.act_fn(self.fc(x))\n",
    "\n",
    "\n",
    "class MLPBinaryClassifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 hidden_dim, \n",
    "                 num_hidden_layers, \n",
    "                 act_fn=F.relu):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            MLPLayer(input_dim, hidden_dim, act_fn),\n",
    "            *[MLPLayer(hidden_dim, hidden_dim, act_fn)\n",
    "              for _ in range(num_hidden_layers)]\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.net(x)\n",
    "        return self.head(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework hint: you should look at the non-linear activation functions in the [PyTorch documentation](https://docs.pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model\n",
    "Let's go back to looking at author gender in our `/texts`. We're going to actually train our `MLPBinaryClassifier` on tf-idf vectors created from novel chunks. \n",
    "\n",
    "We aren't going to focus too much here on our accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "author",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "wc",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "9597b67b-be59-4766-ac86-6cbda7ddbbdd",
       "rows": [
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "1801.--I have just returned from a visit to my landlord--the solitary neighbour that I shall be troubled with.  This is certainly a beautiful country!  In all England, I do not believe that I could have fixed on a situation so completely removed from the stir of society.  A perfect misanthropist's heaven: and Mr. Heathcliff and I are such a suitable pair to divide the desolation between us.  A capital fellow!  He little imagined how my heart warmed towards him when I beheld his black eyes withdraw so suspiciously under their brows, as I rode up, and when his fingers sheltered themselves, with a jealous resolution, still further in his waistcoat, as I announced my name.",
         "115"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'Mr. Lockwood, your new tenant, sir.  I do myself the honour of calling as soon as possible after my arrival, to express the hope that I have not inconvenienced you by my perseverance in soliciting the occupation of Thrushcross Grange: I heard yesterday you had had some thoughts--'",
         "48"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "The 'walk in' was uttered with closed teeth, and expressed the sentiment, 'Go to the Deuce:' even the gate over which he leant manifested no sympathising movement to the words; and I think that circumstance determined me to accept the invitation: I felt interested in a man who seemed more exaggeratedly reserved than myself.",
         "54"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "When he saw my horse's breast fairly pushing the barrier, he did put out his hand to unchain it, and then sullenly preceded me up the causeway, calling, as we entered the court,--'Joseph, take Mr. Lockwood's horse; and bring up some wine.'",
         "42"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'Here we have the whole establishment of domestics, I suppose,' was the reflection suggested by this compound order.  'No wonder the grass grows up between the flags, and cattle are the only hedge-cutters.'",
         "33"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "Joseph was an elderly, nay, an old man: very old, perhaps, though hale and sinewy.  'The Lord help us!' he soliloquised in an undertone of peevish displeasure, while relieving me of my horse: looking, meantime, in my face so sourly that I charitably conjectured he must have need of divine aid to digest his dinner, and his pious ejaculation had no reference to my unexpected advent.",
         "66"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "Wuthering Heights is the name of Mr. Heathcliff's dwelling.  'Wuthering' being a significant provincial adjective, descriptive of the atmospheric tumult to which its station is exposed in stormy weather.  Pure, bracing ventilation they must have up there at all times, indeed: one may guess the power of the north wind blowing over the edge, by the excessive slant of a few stunted firs at the end of the house; and by a range of gaunt thorns all stretching their limbs one way, as if craving alms of the sun. Happily, the architect had foresight to build it strong: the narrow windows are deeply set in the wall, and the corners defended with large jutting stones.",
         "115"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "Before passing the threshold, I paused to admire a quantity of grotesque carving lavished over the front, and especially about the principal door; above which, among a wilderness of crumbling griffins and shameless little boys, I detected the date '1500,' and the name 'Hareton Earnshaw.' I would have made a few comments, and requested a short history of the place from the surly owner; but his attitude at the door appeared to demand my speedy entrance, or complete departure, and I had no desire to aggravate his impatience previous to inspecting the penetralium.",
         "93"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "One stop brought us into the family sitting-room, without any introductory lobby or passage: they call it here 'the house' pre-eminently.  It includes kitchen and parlour, generally; but I believe at Wuthering Heights the kitchen is forced to retreat altogether into another quarter: at least I distinguished a chatter of tongues, and a clatter of culinary utensils, deep within; and I observed no signs of roasting, boiling, or baking, about the huge fireplace; nor any glitter of copper saucepans and tin cullenders on the walls.  One end, indeed, reflected splendidly both light and heat from ranks of immense pewter dishes, interspersed with silver jugs and tankards, towering row after row, on a vast oak dresser, to the very roof.  The latter had never been under-drawn: its entire anatomy lay bare to an inquiring eye, except where a frame of wood laden with oatcakes and clusters of legs of beef, mutton, and ham, concealed it.  Above the chimney were sundry villainous old guns, and a couple of horse-pistols: and, by way of ornament, three gaudily-painted canisters disposed along its ledge.  The floor was of smooth, white stone; the chairs, high-backed, primitive structures, painted green: one or two heavy black ones lurking in the shade.  In an arch under the dresser reposed a huge, liver-coloured bitch pointer, surrounded by a swarm of squealing puppies; and other dogs haunted other recesses.",
         "228"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "The apartment and furniture would have been nothing extraordinary as belonging to a homely, northern farmer, with a stubborn countenance, and stalwart limbs set out to advantage in knee-breeches and gaiters.  Such an individual seated in his arm-chair, his mug of ale frothing on the round table before him, is to be seen in any circuit of five or six miles among these hills, if you go at the right time after dinner.  But Mr. Heathcliff forms a singular contrast to his abode and style of living.  He is a dark-skinned gipsy in aspect, in dress and manners a gentleman: that is, as much a gentleman as many a country squire: rather slovenly, perhaps, yet not looking amiss with his negligence, because he has an erect and handsome figure; and rather morose.  Possibly, some people might suspect him of a degree of under-bred pride; I have a sympathetic chord within that tells me it is nothing of the sort: I know, by instinct, his reserve springs from an aversion to showy displays of feeling--to manifestations of mutual kindliness.  He'll love and hate equally under cover, and esteem it a species of impertinence to be loved or hated again.  No, I'm running on too fast: I bestow my own attributes over-liberally on him.  Mr. Heathcliff may have entirely dissimilar reasons for keeping his hand out of the way when he meets a would-be acquaintance, to those which actuate me.  Let me hope my constitution is almost peculiar: my dear mother used to say I should never have a comfortable home; and only last summer I proved myself perfectly unworthy of one.",
         "270"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "While enjoying a month of fine weather at the sea-coast, I was thrown into the company of a most fascinating creature: a real goddess in my eyes, as long as she took no notice of me.  I 'never told my love' vocally; still, if looks have language, the merest idiot might have guessed I was over head and ears: she understood me at last, and looked a return--the sweetest of all imaginable looks.  And what did I do?  I confess it with shame--shrunk icily into myself, like a snail; at every glance retired colder and farther; till finally the poor innocent was led to doubt her own senses, and, overwhelmed with confusion at her supposed mistake, persuaded her mamma to decamp.  By this curious turn of disposition I have gained the reputation of deliberate heartlessness; how undeserved, I alone can appreciate.",
         "141"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "I took a seat at the end of the hearthstone opposite that towards which my landlord advanced, and filled up an interval of silence by attempting to caress the canine mother, who had left her nursery, and was sneaking wolfishly to the back of my legs, her lip curled up, and her white teeth watering for a snatch.  My caress provoked a long, guttural gnarl.",
         "65"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'You'd better let the dog alone,' growled Mr. Heathcliff in unison, checking fiercer demonstrations with a punch of his foot.  'She's not accustomed to be spoiled--not kept for a pet.'  Then, striding to a side door, he shouted again, 'Joseph!'",
         "40"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "Joseph mumbled indistinctly in the depths of the cellar, but gave no intimation of ascending; so his master dived down to him, leaving me _vis-a-vis_ the ruffianly bitch and a pair of grim shaggy sheep-dogs, who shared with her a jealous guardianship over all my movements. Not anxious to come in contact with their fangs, I sat still; but, imagining they would scarcely understand tacit insults, I unfortunately indulged in winking and making faces at the trio, and some turn of my physiognomy so irritated madam, that she suddenly broke into a fury and leapt on my knees. I flung her back, and hastened to interpose the table between us. This proceeding aroused the whole hive: half-a-dozen four-footed fiends, of various sizes and ages, issued from hidden dens to the common centre. I felt my heels and coat-laps peculiar subjects of assault; and parrying off the larger combatants as effectually as I could with the poker, I was constrained to demand, aloud, assistance from some of the household in re-establishing peace.",
         "171"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "Mr. Heathcliff and his man climbed the cellar steps with vexatious phlegm: I don't think they moved one second faster than usual, though the hearth was an absolute tempest of worrying and yelping. Happily, an inhabitant of the kitchen made more despatch: a lusty dame, with tucked-up gown, bare arms, and fire-flushed cheeks, rushed into the midst of us flourishing a frying-pan: and used that weapon, and her tongue, to such purpose, that the storm subsided magically, and she only remained, heaving like a sea after a high wind, when her master entered on the scene.",
         "96"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'What the devil, indeed!' I muttered.  'The herd of possessed swine could have had no worse spirits in them than those animals of yours, sir.  You might as well leave a stranger with a brood of tigers!'",
         "37"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'They won't meddle with persons who touch nothing,' he remarked, putting the bottle before me, and restoring the displaced table.  'The dogs do right to be vigilant.  Take a glass of wine?'",
         "32"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'Come, come,' he said, 'you are flurried, Mr. Lockwood.  Here, take a little wine.  Guests are so exceedingly rare in this house that I and my dogs, I am willing to own, hardly know how to receive them.  Your health, sir?'",
         "41"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "I bowed and returned the pledge; beginning to perceive that it would be foolish to sit sulking for the misbehaviour of a pack of curs; besides, I felt loth to yield the fellow further amusement at my expense; since his humour took that turn.  He--probably swayed by prudential consideration of the folly of offending a good tenant--relaxed a little in the laconic style of chipping off his pronouns and auxiliary verbs, and introduced what he supposed would be a subject of interest to me,--a discourse on the advantages and disadvantages of my present place of retirement.  I found him very intelligent on the topics we touched; and before I went home, I was encouraged so far as to volunteer another visit to-morrow.  He evidently wished no repetition of my intrusion.  I shall go, notwithstanding.  It is astonishing how sociable I feel myself compared with him.",
         "145"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "Yesterday afternoon set in misty and cold.  I had half a mind to spend it by my study fire, instead of wading through heath and mud to Wuthering Heights.  On coming up from dinner, however, (N.B.--I dine between twelve and one o'clock; the housekeeper, a matronly lady, taken as a fixture along with the house, could not, or would not, comprehend my request that I might be served at five)--on mounting the stairs with this lazy intention, and stepping into the room, I saw a servant-girl on her knees surrounded by brushes and coal-scuttles, and raising an infernal dust as she extinguished the flames with heaps of cinders.  This spectacle drove me back immediately; I took my hat, and, after a four-miles' walk, arrived at Heathcliff's garden-gate just in time to escape the first feathery flakes of a snow-shower.",
         "139"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "On that bleak hill-top the earth was hard with a black frost, and the air made me shiver through every limb.  Being unable to remove the chain, I jumped over, and, running up the flagged causeway bordered with straggling gooseberry-bushes, knocked vainly for admittance, till my knuckles tingled and the dogs howled.",
         "52"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'Wretched inmates!' I ejaculated, mentally, 'you deserve perpetual isolation from your species for your churlish inhospitality. At least, I would not keep my doors barred in the day-time. I don't care--I will get in!' So resolved, I grasped the latch and shook it vehemently. Vinegar-faced Joseph projected his head from a round window of the barn.",
         "56"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'What are ye for?' he shouted.  'T' maister's down i' t' fowld.  Go round by th' end o' t' laith, if ye went to spake to him.'",
         "27"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "The snow began to drive thickly.  I seized the handle to essay another trial; when a young man without coat, and shouldering a pitchfork, appeared in the yard behind.  He hailed me to follow him, and, after marching through a wash-house, and a paved area containing a coal-shed, pump, and pigeon-cot, we at length arrived in the huge, warm, cheerful apartment where I was formerly received.  It glowed delightfully in the radiance of an immense fire, compounded of coal, peat, and wood; and near the table, laid for a plentiful evening meal, I was pleased to observe the 'missis,' an individual whose existence I had never previously suspected.  I bowed and waited, thinking she would bid me take a seat. She looked at me, leaning back in her chair, and remained motionless and mute.",
         "134"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'Rough weather!' I remarked.  'I'm afraid, Mrs. Heathcliff, the door must bear the consequence of your servants' leisure attendance: I had hard work to make them hear me.'",
         "28"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "She never opened her mouth.  I stared--she stared also: at any rate, she kept her eyes on me in a cool, regardless manner, exceedingly embarrassing and disagreeable.",
         "27"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "I obeyed; and hemmed, and called the villain Juno, who deigned, at this second interview, to move the extreme tip of her tail, in token of owning my acquaintance.",
         "29"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "Unluckily, it was a heap of dead rabbits.  I hemmed once more, and drew closer to the hearth, repeating my comment on the wildness of the evening.",
         "27"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "Her position before was sheltered from the light; now, I had a distinct view of her whole figure and countenance.  She was slender, and apparently scarcely past girlhood: an admirable form, and the most exquisite little face that I have ever had the pleasure of beholding; small features, very fair; flaxen ringlets, or rather golden, hanging loose on her delicate neck; and eyes, had they been agreeable in expression, that would have been irresistible: fortunately for my susceptible heart, the only sentiment they evinced hovered between scorn and a kind of desperation, singularly unnatural to be detected there.  The canisters were almost out of her reach; I made a motion to aid her; she turned upon me as a miser might turn if any one attempted to assist him in counting his gold.",
         "133"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'Were you asked to tea?' she demanded, tying an apron over her neat black frock, and standing with a spoonful of the leaf poised over the pot.",
         "27"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "She flung the tea back, spoon and all, and resumed her chair in a pet; her forehead corrugated, and her red under-lip pushed out, like a child's ready to cry.",
         "30"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "Meanwhile, the young man had slung on to his person a decidedly shabby upper garment, and, erecting himself before the blaze, looked down on me from the corner of his eyes, for all the world as if there were some mortal feud unavenged between us.  I began to doubt whether he were a servant or not: his dress and speech were both rude, entirely devoid of the superiority observable in Mr. and Mrs. Heathcliff; his thick brown curls were rough and uncultivated, his whiskers encroached bearishly over his cheeks, and his hands were embrowned like those of a common labourer: still his bearing was free, almost haughty, and he showed none of a domestic's assiduity in attending on the lady of the house.  In the absence of clear proofs of his condition, I deemed it best to abstain from noticing his curious conduct; and, five minutes afterwards, the entrance of Heathcliff relieved me, in some measure, from my uncomfortable state.",
         "160"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'You see, sir, I am come, according to promise!' I exclaimed, assuming the cheerful; 'and I fear I shall be weather-bound for half an hour, if you can afford me shelter during that space.'",
         "34"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'Half an hour?' he said, shaking the white flakes from his clothes; 'I wonder you should select the thick of a snow-storm to ramble about in.  Do you know that you run a risk of being lost in the marshes?  People familiar with these moors often miss their road on such evenings; and I can tell you there is no chance of a change at present.'",
         "66"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'Get it ready, will you?' was the answer, uttered so savagely that I started.  The tone in which the words were said revealed a genuine bad nature.  I no longer felt inclined to call Heathcliff a capital fellow. When the preparations were finished, he invited me with--'Now, sir, bring forward your chair.'  And we all, including the rustic youth, drew round the table: an austere silence prevailing while we discussed our meal.",
         "72"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "I thought, if I had caused the cloud, it was my duty to make an effort to dispel it.  They could not every day sit so grim and taciturn; and it was impossible, however ill-tempered they might be, that the universal scowl they wore was their every-day countenance.",
         "48"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'It is strange,' I began, in the interval of swallowing one cup of tea and receiving another--'it is strange how custom can mould our tastes and ideas: many could not imagine the existence of happiness in a life of such complete exile from the world as you spend, Mr. Heathcliff; yet, I'll venture to say, that, surrounded by your family, and with your amiable lady as the presiding genius over your home and heart--'",
         "74"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'Well, yes--oh, you would intimate that her spirit has taken the post of ministering angel, and guards the fortunes of Wuthering Heights, even when her body is gone.  Is that it?'",
         "31"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "Perceiving myself in a blunder, I attempted to correct it.  I might have seen there was too great a disparity between the ages of the parties to make it likely that they were man and wife.  One was about forty: a period of mental vigour at which men seldom cherish the delusion of being married for love by girls: that dream is reserved for the solace of our declining years.  The other did not look seventeen.",
         "76"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "Then it flashed upon me--'The clown at my elbow, who is drinking his tea out of a basin and eating his bread with unwashed hands, may be her husband: Heathcliff junior, of course.  Here is the consequence of being buried alive: she has thrown herself away upon that boor from sheer ignorance that better individuals existed!  A sad pity--I must beware how I cause her to regret her choice.'  The last reflection may seem conceited; it was not.  My neighbour struck me as bordering on repulsive; I knew, through experience, that I was tolerably attractive.",
         "95"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'Mrs. Heathcliff is my daughter-in-law,' said Heathcliff, corroborating my surmise.  He turned, as he spoke, a peculiar look in her direction: a look of hatred; unless he has a most perverse set of facial muscles that will not, like those of other people, interpret the language of his soul.",
         "49"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "This was worse than before: the youth grew crimson, and clenched his fist, with every appearance of a meditated assault.  But he seemed to recollect himself presently, and smothered the storm in a brutal curse, muttered on my behalf: which, however, I took care not to notice.",
         "47"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'Unhappy in your conjectures, sir,' observed my host; 'we neither of us have the privilege of owning your good fairy; her mate is dead.  I said she was my daughter-in-law: therefore, she must have married my son.'",
         "37"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "He fixed his eye on me longer than I cared to return the stare, for fear I might be tempted either to box his ears or render my hilarity audible. I began to feel unmistakably out of place in that pleasant family circle. The dismal spiritual atmosphere overcame, and more than neutralised, the glowing physical comforts round me; and I resolved to be cautious how I ventured under those rafters a third time.",
         "73"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "The business of eating being concluded, and no one uttering a word of sociable conversation, I approached a window to examine the weather.  A sorrowful sight I saw: dark night coming down prematurely, and sky and hills mingled in one bitter whirl of wind and suffocating snow.",
         "47"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'I don't think it possible for me to get home now without a guide,' I could not help exclaiming.  'The roads will be buried already; and, if they were bare, I could scarcely distinguish a foot in advance.'",
         "38"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'Hareton, drive those dozen sheep into the barn porch.  They'll be covered if left in the fold all night: and put a plank before them,' said Heathcliff.",
         "27"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "There was no reply to my question; and on looking round I saw only Joseph bringing in a pail of porridge for the dogs, and Mrs. Heathcliff leaning over the fire, diverting herself with burning a bundle of matches which had fallen from the chimney-piece as she restored the tea-canister to its place.  The former, when he had deposited his burden, took a critical survey of the room, and in cracked tones grated out--'Aw wonder how yah can faishion to stand thear i' idleness un war, when all on 'ems goan out!  Bud yah're a nowt, and it's no use talking--yah'll niver mend o'yer ill ways, but goa raight to t' divil, like yer mother afore ye!'",
         "117"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "I imagined, for a moment, that this piece of eloquence was addressed to me; and, sufficiently enraged, stepped towards the aged rascal with an intention of kicking him out of the door.  Mrs. Heathcliff, however, checked me by her answer.",
         "40"
        ],
        [
         "0",
         "B-Bronte_E-Wuthering_Heights-1847-F.txt",
         "Bronte_E",
         "Wuthering_Heights",
         "1847",
         "F",
         "'You scandalous old hypocrite!' she replied.  'Are you not afraid of being carried away bodily, whenever you mention the devil's name?  I warn you to refrain from provoking me, or I'll ask your abduction as a special favour!  Stop! look here, Joseph,' she continued, taking a long, dark book from a shelf; 'I'll show you how far I've progressed in the Black Art: I shall soon be competent to make a clear house of it.  The red cow didn't die by chance; and your rheumatism can hardly be reckoned among providential visitations!'",
         "92"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 54075
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>gender</th>\n",
       "      <th>text</th>\n",
       "      <th>wc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Bronte_E-Wuthering_Heights-1847-F.txt</td>\n",
       "      <td>Bronte_E</td>\n",
       "      <td>Wuthering_Heights</td>\n",
       "      <td>1847</td>\n",
       "      <td>F</td>\n",
       "      <td>1801.--I have just returned from a visit to my...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Bronte_E-Wuthering_Heights-1847-F.txt</td>\n",
       "      <td>Bronte_E</td>\n",
       "      <td>Wuthering_Heights</td>\n",
       "      <td>1847</td>\n",
       "      <td>F</td>\n",
       "      <td>'Mr. Lockwood, your new tenant, sir.  I do mys...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Bronte_E-Wuthering_Heights-1847-F.txt</td>\n",
       "      <td>Bronte_E</td>\n",
       "      <td>Wuthering_Heights</td>\n",
       "      <td>1847</td>\n",
       "      <td>F</td>\n",
       "      <td>The 'walk in' was uttered with closed teeth, a...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Bronte_E-Wuthering_Heights-1847-F.txt</td>\n",
       "      <td>Bronte_E</td>\n",
       "      <td>Wuthering_Heights</td>\n",
       "      <td>1847</td>\n",
       "      <td>F</td>\n",
       "      <td>When he saw my horse's breast fairly pushing t...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-Bronte_E-Wuthering_Heights-1847-F.txt</td>\n",
       "      <td>Bronte_E</td>\n",
       "      <td>Wuthering_Heights</td>\n",
       "      <td>1847</td>\n",
       "      <td>F</td>\n",
       "      <td>'Here we have the whole establishment of domes...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A-Norris-Pit-1903-M.txt</td>\n",
       "      <td>Norris</td>\n",
       "      <td>Pit</td>\n",
       "      <td>1903</td>\n",
       "      <td>M</td>\n",
       "      <td>For a moment, vague, dark perplexities assaile...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A-Norris-Pit-1903-M.txt</td>\n",
       "      <td>Norris</td>\n",
       "      <td>Pit</td>\n",
       "      <td>1903</td>\n",
       "      <td>M</td>\n",
       "      <td>She did not know. But as she searched, trouble...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A-Norris-Pit-1903-M.txt</td>\n",
       "      <td>Norris</td>\n",
       "      <td>Pit</td>\n",
       "      <td>1903</td>\n",
       "      <td>M</td>\n",
       "      <td>She looked out quickly, on either hand, throug...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A-Norris-Pit-1903-M.txt</td>\n",
       "      <td>Norris</td>\n",
       "      <td>Pit</td>\n",
       "      <td>1903</td>\n",
       "      <td>M</td>\n",
       "      <td>All at once, intuitively, Laura turned in her ...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A-Norris-Pit-1903-M.txt</td>\n",
       "      <td>Norris</td>\n",
       "      <td>Pit</td>\n",
       "      <td>1903</td>\n",
       "      <td>M</td>\n",
       "      <td>And this was the last impression of the part o...</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54075 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       path    author              title  \\\n",
       "0   B-Bronte_E-Wuthering_Heights-1847-F.txt  Bronte_E  Wuthering_Heights   \n",
       "0   B-Bronte_E-Wuthering_Heights-1847-F.txt  Bronte_E  Wuthering_Heights   \n",
       "0   B-Bronte_E-Wuthering_Heights-1847-F.txt  Bronte_E  Wuthering_Heights   \n",
       "0   B-Bronte_E-Wuthering_Heights-1847-F.txt  Bronte_E  Wuthering_Heights   \n",
       "0   B-Bronte_E-Wuthering_Heights-1847-F.txt  Bronte_E  Wuthering_Heights   \n",
       "..                                      ...       ...                ...   \n",
       "40                  A-Norris-Pit-1903-M.txt    Norris                Pit   \n",
       "40                  A-Norris-Pit-1903-M.txt    Norris                Pit   \n",
       "40                  A-Norris-Pit-1903-M.txt    Norris                Pit   \n",
       "40                  A-Norris-Pit-1903-M.txt    Norris                Pit   \n",
       "40                  A-Norris-Pit-1903-M.txt    Norris                Pit   \n",
       "\n",
       "    year gender                                               text   wc  \n",
       "0   1847      F  1801.--I have just returned from a visit to my...  115  \n",
       "0   1847      F  'Mr. Lockwood, your new tenant, sir.  I do mys...   48  \n",
       "0   1847      F  The 'walk in' was uttered with closed teeth, a...   54  \n",
       "0   1847      F  When he saw my horse's breast fairly pushing t...   42  \n",
       "0   1847      F  'Here we have the whole establishment of domes...   33  \n",
       "..   ...    ...                                                ...  ...  \n",
       "40  1903      M  For a moment, vague, dark perplexities assaile...   55  \n",
       "40  1903      M  She did not know. But as she searched, trouble...   45  \n",
       "40  1903      M  She looked out quickly, on either hand, throug...   52  \n",
       "40  1903      M  All at once, intuitively, Laura turned in her ...   94  \n",
       "40  1903      M  And this was the last impression of the part o...   79  \n",
       "\n",
       "[54075 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember this from Lecture 9.5?\n",
    "\n",
    "root_dir = \"../data/texts\"\n",
    "\n",
    "book_paths = os.listdir(\"../data/texts\")\n",
    "\n",
    "def get_txt_file(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        file = f.read()\n",
    "    return file\n",
    "\n",
    "texts = [get_txt_file(os.path.join(root_dir, p))\n",
    "         for p in book_paths]\n",
    "\n",
    "pattern = re.compile(r\"^[ABFO]-(.+)-(.+)-(\\d{4})-([FM]).txt$\")\n",
    "\n",
    "columns = [\"path\", \"author\", \"title\", \"year\", \"gender\", \"text\"]\n",
    "\n",
    "parsed_metadata = [[p] + list(re.search(pattern, p).groups()) + [texts[i]]\n",
    "                   for i, p in enumerate(book_paths)]\n",
    "\n",
    "df = pd.DataFrame(parsed_metadata, columns=columns)\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: re.split(r\"\\n+\\s*\\n*\", x))\n",
    "df[\"year\"] = df.year.astype(int)\n",
    "\n",
    "df = df.explode(\"text\")\n",
    "\n",
    "df[\"wc\"] = df.text.apply(lambda x: len(x.split()))\n",
    "\n",
    "min_length, max_length = (25, 1000) # Filter by length of text\n",
    "\n",
    "df = df[(df[\"wc\"] > min_length) & (df[\"wc\"] < max_length)]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "f7ed6dba-eac7-4d70-88d6-da4719ccbdb9",
       "rows": [
        [
         "M",
         "27679"
        ],
        [
         "F",
         "26396"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "gender\n",
       "M    27679\n",
       "F    26396\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=256  # Limit dimensionality of our X.\n",
    ")                     # These features won't be great, but \n",
    "                      # they'll be useful for a demonstration.\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(df.text)\n",
    "y = df.gender.to_numpy() == \"M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54075, 256)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a train-test split. In reality, we'd want to split into train, test, and eval sets. While training, we'd evaluate on eval, then evaluate on test only after we're done training. We're simplifying things here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tfidf.astype(np.float32), y.astype(np.float32), train_size=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "First, score a simple logisitic regression classifier on word embedding data. This is **not** a neural classifier. We'll use it as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.640499306518724\n",
      "Majority Baseline:  0.5101248\n"
     ]
    }
   ],
   "source": [
    "lrc = LogisticRegression().fit(X_train, y_train)\n",
    "lr_baseline = lrc.score(X_test, y_test)\n",
    "print(\"Test accuracy: \", lr_baseline) \n",
    "print(\"Majority Baseline: \", y_test.sum()/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch training loop\n",
    "\n",
    "You don't need to understand what's going on here in detail. A vibe-level understanding of the training loop is fine. Pay more attention to what's going on in `eval_model`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, X, y, device, batch_size=100):\n",
    "    y_hats = []\n",
    "    model.eval() # Put model in eval mode\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        with torch.no_grad(): # Don't need gradients\n",
    "            x_batch = torch.tensor(X[i:i+batch_size].todense()).to(device)\n",
    "            y_hat = model(x_batch).cpu().squeeze().numpy()\n",
    "            y_hats.append(y_hat)\n",
    "    y_hats = np.concat(y_hats) >= .5\n",
    "    return accuracy_score(y.astype(bool), y_hats)\n",
    "\n",
    "def train_model(model, X_train, y_train, X_test, y_test, \n",
    "                num_epochs=5, batch_size=100, lr=1e-3, verbose=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: Our MLP\n",
    "        X_train, X_test: Sparse matrices of tf-idf values (train, test)\n",
    "        y_train, y_test: binary labels (train, test)\n",
    "        num_epochs: Number of epochs (times we train on all of our train data)\n",
    "        batch_size: Number of samples per training step\n",
    "        lr: Learning rate (hyperparameter for the optimizer, basically how much we update\n",
    "            model params per step)\n",
    "        \n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr) \n",
    "    \n",
    "    model.to(device)    # Move the model to GPU if we have one\n",
    "    for epoch in range(num_epochs):  \n",
    "        # Training\n",
    "        model.train()   # Put model in training mode\n",
    "        for i in range(0, X_train.shape[0], batch_size):\n",
    "            optimizer.zero_grad()   # Zero gradients every training step\n",
    "\n",
    "            x_batch = torch.tensor( # Convert our Xs and ys to Tensors on the right device\n",
    "                X_train[i:i+batch_size].todense()\n",
    "            ).to(device)\n",
    "            y_batch = torch.tensor(y_train[i:i+batch_size]).to(device)    \n",
    "\n",
    "            y_hat = model(x_batch)  # Get our model output\n",
    "\n",
    "            loss = F.binary_cross_entropy(y_hat.squeeze(), y_batch) # Compute loss\n",
    "\n",
    "            loss.backward() # Backprop\n",
    "\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Evaluation\n",
    "        if verbose:\n",
    "            acc = eval_model(\n",
    "                model, X_test, y_test, device, batch_size=batch_size\n",
    "            )\n",
    "            print(f\"Epoch {epoch}:\\n\\tLast step loss: {loss.item()}\\n\\tEval acc: {acc}\")\n",
    "        elif epoch + 1 == num_epochs:\n",
    "            acc = eval_model(\n",
    "                model, X_test, y_test, device, batch_size=batch_size\n",
    "            )\n",
    "\n",
    "    return acc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's train both our simple, `MyFirstMLP` model as well as an MLP with many more layers. What do you expect will happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "\tLast step loss: 0.6617153286933899\n",
      "\tEval acc: 0.6378178455848359\n",
      "Epoch 1:\n",
      "\tLast step loss: 0.6498311161994934\n",
      "\tEval acc: 0.6408691631992602\n",
      "Epoch 2:\n",
      "\tLast step loss: 0.6452489495277405\n",
      "\tEval acc: 0.6420711974110033\n",
      "Epoch 3:\n",
      "\tLast step loss: 0.6434369683265686\n",
      "\tEval acc: 0.6426259824318077\n",
      "Epoch 4:\n",
      "\tLast step loss: 0.6400379538536072\n",
      "\tEval acc: 0.6462320850670366\n",
      "Epoch 5:\n",
      "\tLast step loss: 0.6353148818016052\n",
      "\tEval acc: 0.6471567267683772\n",
      "Epoch 6:\n",
      "\tLast step loss: 0.6284622550010681\n",
      "\tEval acc: 0.6483587609801202\n",
      "Epoch 7:\n",
      "\tLast step loss: 0.6220479607582092\n",
      "\tEval acc: 0.6515950069348128\n",
      "Epoch 8:\n",
      "\tLast step loss: 0.6145092248916626\n",
      "\tEval acc: 0.6549237170596394\n",
      "Epoch 9:\n",
      "\tLast step loss: 0.6076176166534424\n",
      "\tEval acc: 0.6588996763754046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6588996763754046"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_mlp = MyFirstMLP(X_train.shape[-1], 32)\n",
    "\n",
    "train_model(simple_mlp, X_train, y_train, X_test, y_test, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.640499306518724"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "\tLast step loss: 0.6628468036651611\n",
      "\tEval acc: 0.6388349514563106\n",
      "Epoch 1:\n",
      "\tLast step loss: 0.6492152214050293\n",
      "\tEval acc: 0.6431807674526121\n",
      "Epoch 2:\n",
      "\tLast step loss: 0.6348750591278076\n",
      "\tEval acc: 0.6560332871012483\n",
      "Epoch 3:\n",
      "\tLast step loss: 0.5980568528175354\n",
      "\tEval acc: 0.664447526583449\n",
      "Epoch 4:\n",
      "\tLast step loss: 0.550435483455658\n",
      "\tEval acc: 0.6688858067498844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6688858067498844"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_mlp = MLPBinaryClassifier(X_train.shape[-1], 32, 5)\n",
    "\n",
    "train_model(big_mlp, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though we've been holding learning rate and batch size constant, these are important hyperparameters that can have a significant impact on the training and performance of your model. Let's look at our simple MLP again and see how these hyperparameters impact our accuracy score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [50, 100, 200]\n",
    "lrs = [5e-2, 1e-2, 5e-3, 1e-3, 5e-4, 1e-4]\n",
    "\n",
    "results = np.zeros((len(lrs), len(batch_sizes)))\n",
    "for i, lr in enumerate(lrs):\n",
    "    for j, bsz in enumerate(batch_sizes):\n",
    "        model = MyFirstMLP(X_train.shape[-1], 64)\n",
    "        acc = train_model(\n",
    "            model, X_train, y_train, X_test, y_test, \n",
    "            lr=lr, batch_size=bsz, verbose=False\n",
    "        )\n",
    "        results[i, j] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(\n",
    "    data=results,\n",
    "    xticklabels=batch_sizes,\n",
    "    yticklabels=lrs, \n",
    "    annot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this suggest about the relationship between learning rate and batch size for our data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
