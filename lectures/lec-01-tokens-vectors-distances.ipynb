{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO 3350/6350\n",
    "\n",
    "## Lecture 01: Tokens, vectorization, and distance metrics\n",
    "\n",
    "## To do\n",
    "\n",
    "* Friday sections\n",
    "  * Be prepared to discuss the reading in depth (Healy)\n",
    "  * We'll also go over how to set up Python virtual environments\n",
    "* No lecture next Monday (Labor Day)\n",
    "* Extra credit for good, consistent answers on Ed\n",
    "* Study groups are great for homeworks\n",
    "* Questions?\n",
    "\n",
    "## A toy example\n",
    "\n",
    "Does anyone recognize the puzzle below? \n",
    "\n",
    "![](images/connections_puzzle.png)\n",
    "\n",
    "What is the goal of this puzzle? How do you go about solving it? \n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "Answers: \n",
    "\n",
    "![](images/connections_answers.png)\n",
    "\n",
    "## What does this have to do with this class?\n",
    "\n",
    "One goal of humanistic inquiry and of scientific research is to compare objects, so that we can gather them into types and compare any one object to others that we observe. Think of biological species or literary genres or historical eras. But how can we measure the difference or similarity between objects that are, after all, always necessarily individual and unique?\n",
    "\n",
    "* Measuring the *properties* of objects lets us compare those objects to one another.\n",
    "  * But ... *which* properties?\n",
    " \n",
    "## What is a vector?\n",
    "\n",
    "An ordered collection of numbers that locate a point in space relative to a shared reference point (called the *origin*).\n",
    "\n",
    "* We can also think of vectors as representing the quantified *features* of an object.\n",
    "* Vectors are usually written as *row matrices*, or just as lists: $vec = [1.0, 0.5, 3.0, 1.2]$\n",
    "* Vectors have as many *dimensions* as there are features of the object to represent.\n",
    "  * The number of features to represent is a choice of the experiment. There is no correct choice, though some choices are better than others for a given purpose.\n",
    "  * You will encounter **sparse vectors**, where most values are zero, and **dense vectors**, where most values are non-zero. \n",
    "* What is **vectorization**?\n",
    "  * The process of transforming an object into its vector representation, typically by measuring some of the object's properties.\n",
    "\n",
    "* Establishing a vector representation allows us to define a **distance metric** between objects that aren't straightforwardly spatial.\n",
    "  * \"Distance\" is a metaphor. Ditto \"similarity.\"\n",
    "  * Nothing is, in itself, like or unlike anything else. \n",
    "    * We sometimes seek to assert that objects are similar by erasing aspects of their particularity.\n",
    "  * Measuring similarity and difference are (always and only) interpretive interventions.\n",
    "  \n",
    "## A spatial example\n",
    "\n",
    "Consider this map of central campus:\n",
    "\n",
    "![](images/cornell_map.png)\n",
    "\n",
    "**How far apart are Gates Hall (purple star) and the clock tower (orange star)?**\n",
    "\n",
    "What do we need to know or define in order to answer this question?\n",
    "\n",
    "* Where is each building in physical space.\n",
    "  * Latitude/longitude; meters north/south and east/west of the book store; etc.\n",
    "* How do we want to measure the distance between them (walking, driving, flying, tunneling, ...). Minutes or miles?\n",
    "\n",
    "Normal, boring answer: about 0.4 miles on foot via Campus Rd and Ho Plaza, or a bit less if you cut some corners, or less than 0.3 miles if you can fly.\n",
    "\n",
    "| Clock tower | Gates Hall |\n",
    "| --- | --- | \n",
    "| ![](images/clock_tower.jpg) | ![](images/gates.jpg) |\n",
    "\n",
    "More interesting version: How far apart are these buildings conceptually? Architecturally? Historically? \n",
    "\n",
    "* What are the features and metrics you would use to answer this question?\n",
    "* This is a lot more like the problem of comparing texts.\n",
    "\n",
    "## A textual example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'My cat likes water.')\n",
      "(1, 'The dog eats food.')\n",
      "(2, 'The dog and the cat play together.')\n",
      "(3, 'A dog and a cat meet another dog and cat.')\n",
      "(4, 'The end.')\n"
     ]
    }
   ],
   "source": [
    "text = '''\\\n",
    "My cat likes water.\n",
    "The dog eats food.\n",
    "The dog and the cat play together.\n",
    "A dog and a cat meet another dog and cat.\n",
    "The end.'''\n",
    "\n",
    "# Print with sentence numbers\n",
    "for line in enumerate(text.split('\\n')):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us stipulate that we want to compare these five sentences according to their \"*dogness*\" and \"*catness*.\" We care about those two aspects alone, nothing else.\n",
    "\n",
    "Let's develop some intuitions here:\n",
    "\n",
    "* Sentences 0 and 1 are as far apart as can be: 0 is about cats, 1 is about dogs.\n",
    "* Sentence 2 lies between 0 and 1. It contains a mix of dogness and catness.\n",
    "* Sentence 3 is kind of like sentence 2, but it has twice as much of both dogness and catness.\n",
    "  * How different are sentences 2 and 3? (There's no objectively correct answer.)\n",
    "* Sentence 4 is a zero point. It has no dogness or catness.\n",
    "\n",
    "### Count relevant words\n",
    "\n",
    "||**cat**|**dog**|\n",
    "|---|---|---|\n",
    "|**sentence**| | |\n",
    "|0|1|0|\n",
    "|1|0|1|\n",
    "|2|1|1|\n",
    "|3|2|2|\n",
    "|4|0|0|\n",
    "\n",
    "The **vector representation** of sentence 0 is `[1, 0]`. The vector representation of sentence 3 is `[2, 2]`. And so on ...\n",
    "\n",
    "### Distance measures\n",
    "\n",
    "How far apart are sentences 0 and 1 (and all the rest)?\n",
    "\n",
    "#### Manhattan distance\n",
    "\n",
    "* Also called \"city block\" distance. \n",
    "* Not much used, but easy to understand and to compute (which matters for very large data sets). \n",
    "* Sum of the absolute difference in each dimension.\n",
    "\n",
    "For **sentences 0 and 1**, the Manhattan distance = |1| + |-1| = 2.\n",
    "\n",
    "#### Euclidean distance\n",
    "\n",
    "* Straight-line or \"as the crow flies\" distance. \n",
    "* Widely used in data science, but not always the best choice for textual data.\n",
    "\n",
    "Recall the Pythagorean theorem for the hypotenuse of a triangle: $a^2 = b^2 + c^2$ or $a = \\sqrt{b^2 +c^2}$.\n",
    "\n",
    "For **sentences 0 and 1**, the Euclidean distance = $\\sqrt{1^2 + 1^2} = \\sqrt{2} = 1.414$.\n",
    "\n",
    "OK, but what about the Euclidean distance between **sentence 0 and sentence 3**? Well, that distance = $\\sqrt{1^2 + 2^2} = \\sqrt{5} = 2.24$.\n",
    "\n",
    "And between **sentences 2 and 3** (both balanced 50:50 between dogs and cats)? That's 1.4 again, the same as the distance between sentences 0 and 1 (which, recall, are totally divergent in dog/cat content).\n",
    "\n",
    "An obvious improvement in this case would be to **normalize word counts by document length**.\n",
    "\n",
    "#### Cosine distance\n",
    "\n",
    "Maybe instead of distance, we could measure the difference in **direction** from the origin between points.\n",
    "\n",
    "* **Sentences 0 and 1** are 90 degrees apart.\n",
    "* **Sentences 2 and 3** are 0 degrees apart.\n",
    "* **Sentences 0 and 1** are each 45 degrees away from **sentences 2 and 3**.\n",
    "\n",
    "Now, recall the values of the **cosine** of an angle between 0 and 90 degrees. \n",
    "\n",
    "So, the cosines of the angles between sentences are:\n",
    "\n",
    "sentences|angle|cosine\n",
    "---|---|---\n",
    "0 and 1|90|0\n",
    "2 and 3|0|1\n",
    "0 and 2|45|0.707\n",
    "0 and 3|45|0.707\n",
    "1 and 2|45|0.707\n",
    "\n",
    "\n",
    "![](images/cosine.png)\n",
    "\n",
    "\n",
    "We could then transform these cosine **similarities** into **distances** by subtracting them from 1, so that the most *dissimilar* sentences (like 0 and 1) have the greatest distance between them.\n",
    "\n",
    "The big advantage here is that we don't need to worry about getting length normalization right. Cosine distance is often a good choice for text similarity tasks.\n",
    "\n",
    "#### Higher dimensions\n",
    "\n",
    "All of these metrics can be calculated in arbitrarily many dimensions. Which is good, because textual data is often very high-dimensional. Imagine counting the occurrences of each word type in a large corpus of novels or historical documents. Can easily be tens of thousands of dimensions.\n",
    "\n",
    "## In the real world\n",
    "\n",
    "* There's nothing wrong with any of these vectorizations and distance metrics, exactly, but they're not state of the art.\n",
    "* If you've done some recent NLP work, you'll know that, at the very least, you'd want to use static word embeddings in place of raw tokens.\n",
    "  * This allows you to capture the similarity of meaning between, e.g., \"cat\" and \"kitten.\"\n",
    "  * Word counts alone represent any two distinct word types as (entirely) separate dimensions, so \"cat\" and \"kitten\" have the same inherent relationship (none) as \"cat\" and \"dog\" or \"cat\" and \"algebraic\".\n",
    "* If you were especially ambitious, you'd be looking at something like BERT or GPT-*, etc.\n",
    "    * These transformer-based methods allow for *contextual* embeddings, that is, they represent a word token differently depending on the context in which it appears, so that the representation of \"bank\" in \"my money is in the bank\" is different from the the representation of \"bank\" in \"we walked along the bank of the river.\"\n",
    "* We'll cover both static and contextual embeddings later this semester.\n",
    "* And then you might want features that correspond to aspects of a text other than the specific words it contains.\n",
    "    * When was it written?\n",
    "    * By *whom* was it written?\n",
    "    * How long is it?\n",
    "    * In what style is it written?\n",
    "    * Who read it?\n",
    "    * How much did it cost?\n",
    "    * How many people read or reviewed it?\n",
    "    * What else did its readers also read?\n",
    "    * And so on ...\n",
    "\n",
    "Here, though, we're trying to grasp the *idea* behind document similarity, on which all of these methods depend: transform text into a numeric representation of its features (often, a representation of its content or meaning), then quantify the difference or similarity between those numeric representations.\n",
    "\n",
    "## In the problem set world\n",
    "\n",
    "We'll dig into how, as a practical matter, we can vectorize texts and calclulate distance metrics in this week's problem set.\n",
    "\n",
    "We'll use `scikit-learn` to implement vectorization and distance metrics. The `scikit-learn` API almost always involves *three* steps:\n",
    "\n",
    "1. Instantiate a learning object (such as a vectorizer, regressor, classifier, etc.). This is the object that will hold the parameters of your fitted model.\n",
    "1. Call the instantiated learning object's `.fit()` method, passing in your data. This allows the model to learn the optimal parameters from your data.\n",
    "1. Call the fitted model's `.transform()` or `.predict()` method, passing in either the same data from the `fit` step or new data. This step uses the fitted model to generate outputs given the input data you supply.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat' 'dog']\n",
      "[[1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# get example text as one doc per line\n",
    "docs = [sent for sent in text.split('\\n')]\n",
    "\n",
    "# instantiate vectorizer object\n",
    "#  note setup options\n",
    "vectorizer = CountVectorizer(\n",
    "    vocabulary=['cat', 'dog']\n",
    ")\n",
    "\n",
    "# fit to data\n",
    "vectorizer.fit(docs)\n",
    "\n",
    "# transform docs to features\n",
    "features = vectorizer.transform(docs)\n",
    "\n",
    "# print output feature matrix\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(features.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 6 stored elements and shape (5, 2)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(vocabulary=[&#x27;cat&#x27;, &#x27;dog&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CountVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">input&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;content&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('encoding',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">encoding&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;utf-8&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decode_error',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">decode_error&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;strict&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('strip_accents',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">strip_accents&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('lowercase',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">lowercase&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('preprocessor',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">preprocessor&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tokenizer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tokenizer&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('stop_words',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">stop_words&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('token_pattern',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">token_pattern&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;(?u)\\\\b\\\\w\\\\w+\\\\b&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ngram_range',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ngram_range&nbsp;</td>\n",
       "            <td class=\"value\">(1, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('analyzer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">analyzer&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;word&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_df&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_df&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('vocabulary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">vocabulary&nbsp;</td>\n",
       "            <td class=\"value\">[&#x27;cat&#x27;, &#x27;dog&#x27;]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('binary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">binary&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dtype',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dtype&nbsp;</td>\n",
       "            <td class=\"value\">&lt;class &#x27;numpy.int64&#x27;&gt;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "CountVectorizer(vocabulary=['cat', 'dog'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distances\n",
      "[[0.   1.41 1.   2.24 1.  ]\n",
      " [1.41 0.   1.   2.24 1.  ]\n",
      " [1.   1.   0.   1.41 1.41]\n",
      " [2.24 2.24 1.41 0.   2.83]\n",
      " [1.   1.   1.41 2.83 0.  ]]\n",
      "\n",
      "Cosine distances\n",
      "[[0.   1.   0.29 0.29 1.  ]\n",
      " [1.   0.   0.29 0.29 1.  ]\n",
      " [0.29 0.29 0.   0.   1.  ]\n",
      " [0.29 0.29 0.   0.   1.  ]\n",
      " [1.   1.   1.   1.   0.  ]]\n",
      "\n",
      "Cosine **similarities**\n",
      "[[1.   0.   0.71 0.71 0.  ]\n",
      " [0.   1.   0.71 0.71 0.  ]\n",
      " [0.71 0.71 1.   1.   0.  ]\n",
      " [0.71 0.71 1.   1.   0.  ]\n",
      " [0.   0.   0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# calculate distances\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances, cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "print(\"Euclidean distances\")\n",
    "print(np.round(euclidean_distances(features),2))\n",
    "\n",
    "print(\"\\nCosine distances\")\n",
    "print(np.round(cosine_distances(features),2))\n",
    "\n",
    "print(\"\\nCosine **similarities**\")\n",
    "print(np.round(cosine_similarity(features),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an exercise, you might try to compute these pairwise distance/similarity matrices using numpy alone. For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine **similarities** (ours)\n",
      "[[1.   0.   0.71 0.71 0.  ]\n",
      " [0.   1.   0.71 0.71 0.  ]\n",
      " [0.71 0.71 1.   1.   0.  ]\n",
      " [0.71 0.71 1.   1.   0.  ]\n",
      " [0.   0.   0.   0.   0.  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pairwise_cosine(X):\n",
    "    normalized = X/(np.linalg.norm(X, axis=1, keepdims=True) + 1e-10) # (N, D) Avoid divide-by-zero errors\n",
    "    return normalized @ normalized.T  # (N, D) @ (D, N) -> (N, N)\n",
    "\n",
    "print(\"Cosine **similarities** (ours)\")\n",
    "print(np.round(pairwise_cosine(features.toarray()),2))\n",
    "\n",
    "# Same as sklearn?\n",
    "np.allclose(\n",
    "    np.round(pairwise_cosine(features.toarray()),2), \n",
    "    np.round(cosine_similarity(features),2)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there's no shame in using built-in functions like this on large datasets: if you look at the [`sklearn` source code for `pairwise`](https://github.com/scikit-learn/scikit-learn/blob/c5497b7f7/sklearn/metrics/pairwise.py#L1951), they use multithreading to improve performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distances\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FYI, two heatmap visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Euclidean distances\")\n",
    "\n",
    "# quick and dirty\n",
    "plt.imshow(euclidean_distances(features))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prettier\n",
    "sns.heatmap(\n",
    "    euclidean_distances(features),\n",
    "    annot=True,\n",
    "    square=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization considerations\n",
    "\n",
    "What is a token?\n",
    "\n",
    "* The **smallest individually meaningful unit of a document.** Roughly, a word.\n",
    "* But ... as soon as you see \"meaningful,\" you know it's going to be a matter of interpretation.\n",
    "  * *Every single thing you do in text analysis is an interpretive intervention!*\n",
    "* Not all tokens are (single) words. For example:\n",
    "  * **Contractions**. `\"I'm\"` or `\"can't\"`. One token or two?\n",
    "  * **Phrases.** `\"San Francisco\"` or `\"Cornell University\"`. Two tokens or one?\n",
    "    * These are exampled of \"named entities.\" We'll revisit them later in the semester.\n",
    "  * **Punctuation.** Count it at all? Is `\"this\"` the same token as `\"this!\"`? Is `\".\"` or `\";\"` a token on its own?\n",
    "  * **Domain-specific terms.** `\"@user\"`, `\"COVID-19\"`, etc.\n",
    "\n",
    "Tokenization is part of the more-or-less standard text-processing workflow. Other parts of that workflow might include:\n",
    "  * Case regularization/folding\n",
    "  * Punctuation removal\n",
    "  * Lemmatization or stemming\n",
    "  * Sentence segmentation\n",
    "  * Stopword removal\n",
    "  * and more ...\n",
    "  \n",
    "## State of the art\n",
    "\n",
    "A decade ago, using raw tokens for NLP tasks was the best we could do. Today, we generally use static or contextual word *embeddings* in place of tokens. We'll talk about this at length in the second half of the course, but the underlying idea is the same. Words and embeddings are proxies for meaning (which is what we ultimately care about, but is never directly accessible to us). Embeddings are just a way to capture more of the specific meaning of a word as it is used in a given language (static) or linguistic context (contextual).\n",
    "\n",
    "## Tokenization can be domain-specific\n",
    "\n",
    "Note that today's reading assumed some special interests:\n",
    "\n",
    "* Twitter(like) texts\n",
    "* Sentiment as target phenomenon\n",
    "\n",
    "So it worked hard to capture Twitter handles, hashtags, smilies, URLs, etc.\n",
    "\n",
    "The \"right\" way to tokenize depends on your project, on what is meaningful *in context*.\n",
    "If you have different data or different phenomena to investigate, you might tokenize differently.\n",
    "\n",
    "## Approach 1: Split on whitespace\n",
    "\n",
    "A simple, naïve approach, workable for quick-and-dirty work with many Western languages.\n",
    "\n",
    "Consider the sentence:\n",
    "\n",
    "> Cornell is a private, Ivy League university and the land-grant university for New York state.\n",
    "\n",
    "How many tokens does this sentence contain? (count them for yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cornell', 'is', 'a', 'private,', 'Ivy', 'League', 'university', 'and', 'the', 'land-grant', 'university', 'for', 'New', 'York', 'state.']\n",
      "Number of tokens: 15\n"
     ]
    }
   ],
   "source": [
    "cornell = 'Cornell is a private, Ivy League university and the land-grant university for New York state.'\n",
    "tokens = cornell.split()\n",
    "print(tokens)\n",
    "print(\"Number of tokens:\", len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice: `private,` `land-grant` `state.` These aren't wrong *per se*, but ...\n",
    "\n",
    "Maybe we could do better if we just took non-space, non-puctuation strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cornell', 'is', 'a', 'private', 'Ivy', 'League', 'university', 'and', 'the', 'land', 'grant', 'university', 'for', 'New', 'York', 'state']\n",
      "Number of tokens: 16\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "word_pattern = re.compile(r\"[\\w]+\")\n",
    "tokens_re = word_pattern.findall(cornell)\n",
    "print(tokens_re)\n",
    "print(\"Number of tokens:\", len(tokens_re))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular expressions\n",
    "\n",
    "A totally inadequate mini-introduction to an important but annoyingly complex technology.\n",
    "\n",
    "* What is a regular expression (regex)?\n",
    "  * A sequence of characters that define a search pattern.\n",
    "  * That is, it's a text search or matching language.\n",
    "  * Notoriously unreadable and difficult to parse by eye.\n",
    "  \n",
    "Consider the line above:\n",
    "\n",
    "```\n",
    "word_pattern = re.compile(\"[\\w]+\")\n",
    "```\n",
    "\n",
    "The search pattern here is any sequence of one or more (`+`) uniterrupted \"word\" characters (`\\w` = upper- and lowercase letters, plus digits) that occur anywhere in a string. Regexes are usually \"greedy,\" so will continue matching character by character until their condition is not met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t']\n",
      "['the']\n",
      "['these']\n",
      "['these', 'uns']\n",
      "['these', 'ones']\n"
     ]
    }
   ],
   "source": [
    "for word in ['t', 'the', 'these', \"these'uns\", \"these ones\"]:\n",
    "    print(word_pattern.findall(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`re` is Python's regular expression library. `compile` prepares the regular expression for use with text inputs.\n",
    "\n",
    "A few other useful bits of regex syntax:\n",
    "\n",
    "* `.` (period) = any character\n",
    "* `\\s` = whitespace character (space, tab, newline, etc.)\n",
    "* `\\d` = digit\n",
    "* `[abc]` = any character in the set {a, b, c}.\n",
    "* `[^abc]` = negation, any character *except* a, b, or c.\n",
    "* `A*` = zero or more occurrences of the character A; `+` = one or more, `?` = zero or one.\n",
    "* `\\A`, `\\Z`, `^`, and `$` = match only at start or end of a string or line, respectively.\n",
    "* `\\` (backslash) = escape the next character; `\\.` = period, not wildcard.\n",
    "\n",
    "There's a lot more to this. Take a look at the code linked from today's reading, and/or consult a [regex cheat sheet](https://learnbyexample.github.io/cheatsheet/python/python-regex-cheatsheet/).\n",
    "\n",
    "Why use regular expressions?\n",
    "  * A powerful way to find/match/extract substrings from strings and texts.\n",
    "  * Can use regexes to build robust custom tokenizers (as in the reading for today)\n",
    "\n",
    "### NLTK\n",
    "\n",
    "The Natural Language Tool Kit (NLTK) is a Python NLP library that long predates today's transformer models. It includes a bunch of tokenizers, nearly all of them extensible, that will probably perform better than whatever you can hack together for your project.\n",
    "\n",
    "Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cornell', 'is', 'a', 'private', ',', 'Ivy', 'League', 'university', 'and', 'the', 'land-grant', 'university', 'for', 'New', 'York', 'state', '.']\n",
      "Number of tokens: 17\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "tokens_nltk = word_tokenize(cornell)\n",
    "print(tokens_nltk)\n",
    "print('Number of tokens:', len(tokens_nltk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ca', \"n't\", ',', 'I', \"'m\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"can't, I'm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that NLTK treats word-terminal punctuation as a token and is smart about contractions.\n",
    "\n",
    "## Non-English/Non-Western text\n",
    "\n",
    "Whitespace can be a very bad approach if Western typographic conventions don't apply!\n",
    "\n",
    "If you don't know the language:\n",
    "\n",
    "* Ask if you should be doing the work\n",
    "* Lean on libraries\n",
    "\n",
    "### Example from the *New York Times*\n",
    "\n",
    "In a [recent *Times* article](https://www.nytimes.com/2020/09/03/sports/soccer/premier-league-china-contract-television.html) on football broadcasting rights, we find this sentence:\n",
    "\n",
    "**Chinese**\n",
    "\n",
    "> 因受新型冠状病毒危机对足球和其他体育赛事的持续影响，早已面临越来越多亏损的英格兰超级足球联赛周四宣布，因为无法解决与中国合作伙伴的纠纷，已终止了其最赚钱的海外转播合同。\n",
    "\n",
    "**English translation**\n",
    "\n",
    "> The English Premier League, already facing mounting losses because of the continued impact of the coronavirus crisis on soccer and other sporting events, announced on Thursday that it had canceled its most lucrative overseas broadcast contract after it was unable to resolve a dispute with its Chinese partner.\n",
    "\n",
    "Our previous tokenization strategy doesn't work well in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['因受新型冠状病毒危机对足球和其他体育赛事的持续影响，早已面临越来越多亏损的英格兰超级足球联赛周四宣布，因为无法解决与中国合作伙伴的纠纷，已终止了其最赚钱的海外转播合同。']\n",
      "Number of Chinese tokens: 1\n",
      "Number of English tokens: 48\n"
     ]
    }
   ],
   "source": [
    "# Strings\n",
    "zh = '因受新型冠状病毒危机对足球和其他体育赛事的持续影响，早已面临越来越多亏损的英格兰超级足球联赛周四宣布，因为无法解决与中国合作伙伴的纠纷，已终止了其最赚钱的海外转播合同。'\n",
    "en = 'The English Premier League, already facing mounting losses because of the continued impact of the coronavirus crisis on soccer and other sporting events, announced on Thursday that it had canceled its most lucrative overseas broadcast contract after it was unable to resolve a dispute with its Chinese partner.'\n",
    "\n",
    "# Naive approach to tokenization\n",
    "zh_tokens_bad = zh.split()\n",
    "print(zh_tokens_bad)\n",
    "print('Number of Chinese tokens:', len(zh_tokens_bad))\n",
    "\n",
    "# English version\n",
    "en_tokens = en.split()\n",
    "print('Number of English tokens:', len(en_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `jieba` tokenizer\n",
    "\n",
    "See the [`jieba` project GitHub page](https://github.com/fxsjy/jieba) for documentation (in Chinese and in English). `jieba` is one of the packages we installed in our virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/Teaching/info3350-f25/.venv/lib/python3.12/site-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.664 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['因受', '新型', '冠状病毒', '危机', '对', '足球', '和', '其他', '体育赛事', '的', '持续', '影响', '，', '早已', '面临', '越来越', '多', '亏损', '的', '英格兰', '超级', '足球联赛', '周四', '宣布', '，', '因为', '无法', '解决', '与', '中国', '合作伙伴', '的', '纠纷', '，', '已', '终止', '了', '其', '最', '赚钱', '的', '海外', '转播', '合同', '。']\n",
      "Number of Chinese tokens: 45\n"
     ]
    }
   ],
   "source": [
    "# A better approach to tokenizing Chinese-language text\n",
    "import jieba\n",
    "zh_tokens_better = [token for token in jieba.cut(zh)]\n",
    "print(zh_tokens_better)\n",
    "print(\"Number of Chinese tokens:\", len(zh_tokens_better))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization today\n",
    "As you might know, LLMs also use tokenizers to convert strings into digestible, numerical data. These tokenizers are much more complex than what we've been describing here. In fact, they tend to employ something like the NLTK tokenizer above as a \"pre-tokenizer\" prior to actually tokenizing the text for the model. \n",
    "\n",
    "We'll talk about common tokenization techniques used by contemporary LLMs later in the course."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
